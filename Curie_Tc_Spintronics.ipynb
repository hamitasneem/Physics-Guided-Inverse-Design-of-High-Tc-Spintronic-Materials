{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d6a6c91-9fd8-40b5-9bf7-d51a6eab56aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =====================================\n",
    "# INSTALL MISSING DEPENDENCIES (SAFE)\n",
    "# =====================================\n",
    "import sys\n",
    "!{sys.executable} -m pip install seaborn\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "559fa862-a97e-4258-9ab2-faa397f27143",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =====================================\n",
    "# INSTALL REQUIRED EXCEL DEPENDENCY\n",
    "# =====================================\n",
    "import sys\n",
    "!{sys.executable} -m pip install openpyxl\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abac31e2-9ef9-45de-9e4b-61c59da4d7aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "!{sys.executable} -m pip install matminer pymatgen\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bc348a2-1a5a-4e06-9629-d4eca7910319",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "!{sys.executable} -m pip install xgboost lightgbm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1099aa27-93b2-42bb-b0a7-010513f8e3a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ================================\n",
    "# CORE SCIENTIFIC STACK\n",
    "# ================================\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# ================================\n",
    "# VISUALIZATION\n",
    "# ================================\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# ================================\n",
    "# FILE & PATH MANAGEMENT\n",
    "# ================================\n",
    "from pathlib import Path\n",
    "import os\n",
    "\n",
    "# ================================\n",
    "# WARNINGS CONTROL\n",
    "# ================================\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5eadce3a-8510-4dbe-a455-e0c72e36e497",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ================================\n",
    "# GLOBAL PLOT SETTINGS\n",
    "# ================================\n",
    "plt.rcParams.update({\n",
    "    \"figure.figsize\": (7, 5),\n",
    "    \"figure.dpi\": 120,\n",
    "    \"savefig.dpi\": 300,\n",
    "    \"font.size\": 11,\n",
    "    \"axes.labelsize\": 12,\n",
    "    \"axes.titlesize\": 13,\n",
    "    \"legend.fontsize\": 10,\n",
    "    \"xtick.labelsize\": 10,\n",
    "    \"ytick.labelsize\": 10,\n",
    "    \"lines.linewidth\": 2,\n",
    "})\n",
    "sns.set_style(\"whitegrid\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18c2dedc-af09-433e-8458-b177a9cd7423",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ================================\n",
    "# PROJECT ROOT\n",
    "# ================================\n",
    "PROJECT_ROOT = Path(\".\").resolve()\n",
    "\n",
    "# ================================\n",
    "# DATA DIRECTORIES\n",
    "# ================================\n",
    "DATA_RAW_DIR = PROJECT_ROOT / \"data\" / \"raw\"\n",
    "DATA_CLEAN_DIR = PROJECT_ROOT / \"data\" / \"clean\"\n",
    "DATA_INTERIM_DIR = PROJECT_ROOT / \"data\" / \"intermediate\"\n",
    "\n",
    "# ================================\n",
    "# RESULTS DIRECTORIES\n",
    "# ================================\n",
    "RESULTS_DIR = PROJECT_ROOT / \"results\"\n",
    "TABLES_DIR = RESULTS_DIR / \"tables\"\n",
    "FIGURES_DIR = RESULTS_DIR / \"figures\"\n",
    "\n",
    "# ================================\n",
    "# FIGURE SUBDIRECTORIES\n",
    "# ================================\n",
    "FIG_PNG_DIR = FIGURES_DIR / \"png\"\n",
    "FIG_PDF_DIR = FIGURES_DIR / \"pdf\"\n",
    "\n",
    "# ================================\n",
    "# CREATE ALL DIRECTORIES\n",
    "# ================================\n",
    "for d in [\n",
    "    DATA_RAW_DIR, DATA_CLEAN_DIR, DATA_INTERIM_DIR,\n",
    "    RESULTS_DIR, TABLES_DIR,\n",
    "    FIGURES_DIR, FIG_PNG_DIR, FIG_PDF_DIR\n",
    "]:\n",
    "    d.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "print(\"✅ Project directory structure ready.\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "396ec85a-9552-426c-a18a-ff6f8cc3b8d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ================================\n",
    "# STANDARD FILE NAMES (DO NOT CHANGE)\n",
    "# ================================\n",
    "RAW_DATA_FILE = DATA_RAW_DIR / \"Curie_Data_Raw.xlsx\"\n",
    "CLEAN_DATA_FILE = DATA_CLEAN_DIR / \"Curie_Data_Cleaned.csv\"\n",
    "\n",
    "print(\"Raw data file  :\", RAW_DATA_FILE)\n",
    "print(\"Clean data file:\", CLEAN_DATA_FILE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dfe1e02-5372-4ba0-a279-1ac1e6355d9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ================================\n",
    "# UNIFIED FIGURE SAVE FUNCTION\n",
    "# ================================\n",
    "def save_figure(fig, name, tight=True):\n",
    "    \"\"\"\n",
    "    Save figure in both PNG and PDF formats.\n",
    "    \n",
    "    Parameters:\n",
    "    - fig: matplotlib figure object\n",
    "    - name: file name WITHOUT extension\n",
    "    - tight: apply tight_layout before saving\n",
    "    \"\"\"\n",
    "    if tight:\n",
    "        fig.tight_layout()\n",
    "    \n",
    "    png_path = FIG_PNG_DIR / f\"{name}.png\"\n",
    "    pdf_path = FIG_PDF_DIR / f\"{name}.pdf\"\n",
    "    \n",
    "    fig.savefig(png_path, bbox_inches=\"tight\")\n",
    "    fig.savefig(pdf_path, bbox_inches=\"tight\")\n",
    "    \n",
    "    print(f\"Saved: {png_path}\")\n",
    "    print(f\"Saved: {pdf_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bf51f32-c6c4-4841-81e0-17cd7aae1abc",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Python version check OK\")\n",
    "print(\"pandas:\", pd.__version__)\n",
    "print(\"numpy :\", np.__version__)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cd84352-7f89-4486-b030-37aaac41939c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# CELL 1: DATA LOADING & STRICT CLEANING (nat DROPPED)\n",
    "# ============================================================\n",
    "\n",
    "# -------------------------------\n",
    "# 1. Load raw dataset\n",
    "# -------------------------------\n",
    "df_raw = pd.read_excel(RAW_DATA_FILE)\n",
    "\n",
    "print(\"=== RAW DATA (AS LOADED) ===\")\n",
    "print(\"Shape:\", df_raw.shape)\n",
    "print(\"Columns:\", df_raw.columns.tolist())\n",
    "\n",
    "# Save raw snapshot (for traceability)\n",
    "raw_snapshot_path = DATA_INTERIM_DIR / \"Curie_Data_Raw_snapshot.csv\"\n",
    "df_raw.to_csv(raw_snapshot_path, index=False)\n",
    "\n",
    "print(\"Raw snapshot saved to:\", raw_snapshot_path)\n",
    "\n",
    "\n",
    "# -------------------------------\n",
    "# 2. Drop 'nat' column explicitly\n",
    "# -------------------------------\n",
    "if \"nat\" in df_raw.columns:\n",
    "    df_raw = df_raw.drop(columns=[\"nat\"])\n",
    "    print(\"\\n'nat' column dropped.\")\n",
    "else:\n",
    "    print(\"\\n'nat' column not present.\")\n",
    "\n",
    "print(\"Columns after dropping 'nat':\", df_raw.columns.tolist())\n",
    "\n",
    "\n",
    "# -------------------------------\n",
    "# 3. Remove rows with ANY missing values\n",
    "#    (now only checks Material_Name & Curie)\n",
    "# -------------------------------\n",
    "df_no_missing = df_raw.dropna(how=\"any\")\n",
    "\n",
    "print(\"\\n=== AFTER DROPPING MISSING VALUES ===\")\n",
    "print(\"Shape:\", df_no_missing.shape)\n",
    "print(\"Rows removed (missing):\", df_raw.shape[0] - df_no_missing.shape[0])\n",
    "\n",
    "\n",
    "# -------------------------------\n",
    "# 4. Remove duplicate rows\n",
    "# -------------------------------\n",
    "df_clean = df_no_missing.drop_duplicates()\n",
    "\n",
    "print(\"\\n=== AFTER DROPPING DUPLICATES ===\")\n",
    "print(\"Shape:\", df_clean.shape)\n",
    "print(\"Duplicate rows removed:\", df_no_missing.shape[0] - df_clean.shape[0])\n",
    "\n",
    "\n",
    "# -------------------------------\n",
    "# 5. Reset index (critical for reproducibility)\n",
    "# -------------------------------\n",
    "df_clean = df_clean.reset_index(drop=True)\n",
    "\n",
    "\n",
    "# -------------------------------\n",
    "# 6. Save cleaned dataset\n",
    "# -------------------------------\n",
    "df_clean.to_csv(CLEAN_DATA_FILE, index=False)\n",
    "\n",
    "print(\"\\n=== CLEAN DATA SAVED ===\")\n",
    "print(\"Cleaned data file:\", CLEAN_DATA_FILE)\n",
    "\n",
    "\n",
    "# -------------------------------\n",
    "# 7. Save cleaning log (Methods-ready)\n",
    "# -------------------------------\n",
    "cleaning_log = pd.DataFrame({\n",
    "    \"Stage\": [\n",
    "        \"Raw dataset (with nat)\",\n",
    "        \"After dropping nat column\",\n",
    "        \"After removing missing values\",\n",
    "        \"After removing duplicates\"\n",
    "    ],\n",
    "    \"Rows\": [\n",
    "        pd.read_excel(RAW_DATA_FILE).shape[0],\n",
    "        df_raw.shape[0],\n",
    "        df_no_missing.shape[0],\n",
    "        df_clean.shape[0]\n",
    "    ],\n",
    "    \"Columns\": [\n",
    "        3,                      # original columns\n",
    "        df_raw.shape[1],\n",
    "        df_no_missing.shape[1],\n",
    "        df_clean.shape[1]\n",
    "    ]\n",
    "})\n",
    "\n",
    "log_path = RESULTS_DIR / \"data_cleaning_log.csv\"\n",
    "cleaning_log.to_csv(log_path, index=False)\n",
    "\n",
    "print(\"\\nCleaning log saved to:\", log_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3616f144-57c6-43b1-b2b2-1e4296ae6fb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# CELL 2: SANITY CHECKS & Tc DISTRIBUTION\n",
    "# ============================================================\n",
    "\n",
    "# -------------------------------\n",
    "# 1. Load cleaned dataset\n",
    "# -------------------------------\n",
    "df = pd.read_csv(CLEAN_DATA_FILE)\n",
    "\n",
    "print(\"=== CLEAN DATASET LOADED ===\")\n",
    "print(\"Shape:\", df.shape)\n",
    "print(\"Columns:\", df.columns.tolist())\n",
    "\n",
    "# -------------------------------\n",
    "# 2. Basic sanity checks\n",
    "# -------------------------------\n",
    "print(\"\\n=== SANITY CHECKS ===\")\n",
    "print(\"Missing values per column:\")\n",
    "print(df.isnull().sum())\n",
    "\n",
    "print(\"\\nUnique materials:\", df[\"Material_Name\"].nunique())\n",
    "\n",
    "# -------------------------------\n",
    "# 3. Basic Tc statistics\n",
    "# -------------------------------\n",
    "tc_stats = df[\"Curie\"].describe()\n",
    "\n",
    "print(\"\\n=== Curie Temperature Statistics (K) ===\")\n",
    "print(tc_stats)\n",
    "\n",
    "# Save statistics table\n",
    "tc_stats_df = tc_stats.to_frame(name=\"Curie_Temperature_K\")\n",
    "stats_path = TABLES_DIR / \"Curie_Tc_basic_statistics.csv\"\n",
    "tc_stats_df.to_csv(stats_path)\n",
    "\n",
    "print(\"\\nTc statistics table saved to:\", stats_path)\n",
    "\n",
    "# -------------------------------\n",
    "# 4. Histogram: Tc distribution (linear scale)\n",
    "# -------------------------------\n",
    "fig1, ax1 = plt.subplots()\n",
    "\n",
    "ax1.hist(df[\"Curie\"], bins=60)\n",
    "ax1.set_xlabel(\"Curie Temperature (K)\")\n",
    "ax1.set_ylabel(\"Count\")\n",
    "ax1.set_title(\"Distribution of Curie Temperatures (Linear Scale)\")\n",
    "\n",
    "save_figure(fig1, \"Tc_distribution_linear\")\n",
    "\n",
    "plt.close(fig1)\n",
    "\n",
    "# -------------------------------\n",
    "# 5. Histogram: Tc distribution (log scale)\n",
    "# -------------------------------\n",
    "fig2, ax2 = plt.subplots()\n",
    "\n",
    "ax2.hist(df[\"Curie\"], bins=60)\n",
    "ax2.set_xlabel(\"Curie Temperature (K)\")\n",
    "ax2.set_ylabel(\"Count (log scale)\")\n",
    "ax2.set_yscale(\"log\")\n",
    "ax2.set_title(\"Distribution of Curie Temperatures (Log Scale)\")\n",
    "\n",
    "save_figure(fig2, \"Tc_distribution_log\")\n",
    "\n",
    "plt.close(fig2)\n",
    "\n",
    "# -------------------------------\n",
    "# 6. Optional: Boxplot (outlier visibility)\n",
    "# -------------------------------\n",
    "fig3, ax3 = plt.subplots()\n",
    "\n",
    "ax3.boxplot(df[\"Curie\"], vert=False)\n",
    "ax3.set_xlabel(\"Curie Temperature (K)\")\n",
    "ax3.set_title(\"Boxplot of Curie Temperatures\")\n",
    "\n",
    "save_figure(fig3, \"Tc_boxplot\")\n",
    "\n",
    "plt.close(fig3)\n",
    "\n",
    "print(\"\\nCELL 2 completed successfully.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eca4bb4f-1a30-437b-a2e8-6f71ab44a46a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# CELL 3: CHEMISTRY-AWARE INSPECTION\n",
    "# ============================================================\n",
    "\n",
    "import re\n",
    "from collections import Counter\n",
    "\n",
    "# -------------------------------\n",
    "# 1. Helper: parse elements from formula\n",
    "# -------------------------------\n",
    "def extract_elements(formula):\n",
    "    \"\"\"\n",
    "    Extract element symbols from a chemical formula string.\n",
    "    Example: 'Co2Fe0.75V0.25Ge' -> ['Co', 'Fe', 'V', 'Ge']\n",
    "    \"\"\"\n",
    "    return re.findall(r\"[A-Z][a-z]?\", formula)\n",
    "\n",
    "# -------------------------------\n",
    "# 2. Extract elemental information\n",
    "# -------------------------------\n",
    "df[\"elements\"] = df[\"Material_Name\"].apply(extract_elements)\n",
    "df[\"n_elements\"] = df[\"elements\"].apply(lambda x: len(set(x)))\n",
    "\n",
    "# -------------------------------\n",
    "# 3. Identify key magnetic elements\n",
    "# -------------------------------\n",
    "MAGNETIC_3D = {\"Fe\", \"Co\", \"Ni\", \"Mn\", \"Cr\", \"V\"}\n",
    "RARE_EARTHS = {\n",
    "    \"La\",\"Ce\",\"Pr\",\"Nd\",\"Sm\",\"Eu\",\"Gd\",\"Tb\",\"Dy\",\n",
    "    \"Ho\",\"Er\",\"Tm\",\"Yb\",\"Lu\"\n",
    "}\n",
    "\n",
    "df[\"has_3d_TM\"] = df[\"elements\"].apply(\n",
    "    lambda els: any(e in MAGNETIC_3D for e in els)\n",
    ")\n",
    "\n",
    "df[\"has_RE\"] = df[\"elements\"].apply(\n",
    "    lambda els: any(e in RARE_EARTHS for e in els)\n",
    ")\n",
    "\n",
    "# -------------------------------\n",
    "# 4. Chemistry class labels\n",
    "# -------------------------------\n",
    "def classify_material(row):\n",
    "    if row[\"has_RE\"] and row[\"has_3d_TM\"]:\n",
    "        return \"RE–TM hybrid\"\n",
    "    elif row[\"has_RE\"]:\n",
    "        return \"Rare-earth based\"\n",
    "    elif row[\"has_3d_TM\"]:\n",
    "        return \"3d-transition-metal\"\n",
    "    else:\n",
    "        return \"Other\"\n",
    "\n",
    "df[\"chemistry_class\"] = df.apply(classify_material, axis=1)\n",
    "\n",
    "# -------------------------------\n",
    "# 5. Save enriched chemistry table\n",
    "# -------------------------------\n",
    "chem_path = DATA_INTERIM_DIR / \"Curie_Data_Chemistry_Parsed.csv\"\n",
    "df.to_csv(chem_path, index=False)\n",
    "\n",
    "print(\"Chemistry-enriched dataset saved to:\", chem_path)\n",
    "\n",
    "# -------------------------------\n",
    "# 6. Summary tables\n",
    "# -------------------------------\n",
    "class_counts = df[\"chemistry_class\"].value_counts()\n",
    "class_counts_path = TABLES_DIR / \"chemistry_class_counts.csv\"\n",
    "class_counts.to_csv(class_counts_path)\n",
    "\n",
    "print(\"\\nMaterial count by chemistry class:\")\n",
    "print(class_counts)\n",
    "print(\"Saved to:\", class_counts_path)\n",
    "\n",
    "# -------------------------------\n",
    "# 7. Tc statistics by chemistry class\n",
    "# -------------------------------\n",
    "tc_by_class = df.groupby(\"chemistry_class\")[\"Curie\"].describe()\n",
    "tc_by_class_path = TABLES_DIR / \"Tc_by_chemistry_class.csv\"\n",
    "tc_by_class.to_csv(tc_by_class_path)\n",
    "\n",
    "print(\"\\nTc statistics by chemistry class saved to:\", tc_by_class_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c757ec70-9278-48b6-8c7d-ef6abb664255",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# CELL 4A: Tc vs CHEMISTRY CLASS (PUBLICATION FIGURES)\n",
    "# ============================================================\n",
    "\n",
    "# -------------------------------\n",
    "# 1. Load chemistry-enriched dataset\n",
    "# -------------------------------\n",
    "df = pd.read_csv(DATA_INTERIM_DIR / \"Curie_Data_Chemistry_Parsed.csv\")\n",
    "\n",
    "print(\"Dataset loaded for plotting. Shape:\", df.shape)\n",
    "\n",
    "# -------------------------------\n",
    "# 2. Boxplot: Tc by chemistry class\n",
    "# -------------------------------\n",
    "fig1, ax1 = plt.subplots()\n",
    "\n",
    "df.boxplot(\n",
    "    column=\"Curie\",\n",
    "    by=\"chemistry_class\",\n",
    "    ax=ax1,\n",
    "    grid=False\n",
    ")\n",
    "\n",
    "ax1.set_xlabel(\"Chemistry Class\")\n",
    "ax1.set_ylabel(\"Curie Temperature (K)\")\n",
    "ax1.set_title(\"Curie Temperature Distribution by Chemistry Class\")\n",
    "plt.suptitle(\"\")  # remove automatic pandas title\n",
    "\n",
    "save_figure(fig1, \"Tc_by_chemistry_class_boxplot\")\n",
    "plt.close(fig1)\n",
    "\n",
    "# -------------------------------\n",
    "# 3. Violin plot: distribution shape\n",
    "# -------------------------------\n",
    "fig2, ax2 = plt.subplots()\n",
    "\n",
    "sns.violinplot(\n",
    "    data=df,\n",
    "    x=\"chemistry_class\",\n",
    "    y=\"Curie\",\n",
    "    cut=0,\n",
    "    inner=\"quartile\",\n",
    "    ax=ax2\n",
    ")\n",
    "\n",
    "ax2.set_xlabel(\"Chemistry Class\")\n",
    "ax2.set_ylabel(\"Curie Temperature (K)\")\n",
    "ax2.set_title(\"Curie Temperature Distribution (Violin Plot)\")\n",
    "\n",
    "save_figure(fig2, \"Tc_by_chemistry_class_violin\")\n",
    "plt.close(fig2)\n",
    "\n",
    "# -------------------------------\n",
    "# 4. Fraction of high-Tc materials (>300 K)\n",
    "# -------------------------------\n",
    "high_tc_threshold = 300\n",
    "\n",
    "high_tc_fraction = (\n",
    "    df.assign(high_tc=df[\"Curie\"] > high_tc_threshold)\n",
    "      .groupby(\"chemistry_class\")[\"high_tc\"]\n",
    "      .mean()\n",
    "      .sort_values(ascending=False)\n",
    ")\n",
    "\n",
    "high_tc_fraction_path = TABLES_DIR / \"high_Tc_fraction_by_class.csv\"\n",
    "high_tc_fraction.to_csv(high_tc_fraction_path)\n",
    "\n",
    "print(\"\\nFraction of materials with Tc >\", high_tc_threshold, \"K:\")\n",
    "print(high_tc_fraction)\n",
    "print(\"Saved to:\", high_tc_fraction_path)\n",
    "\n",
    "print(\"\\nCELL 4A completed successfully.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d6d8372-f85e-46a1-96d9-54a993b37ed5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# CELL X: SAFE COMPOSITION PARSING & FILTERING\n",
    "# ============================================================\n",
    "\n",
    "from pymatgen.core import Composition\n",
    "import pandas as pd\n",
    "\n",
    "# Load chemistry-parsed dataset\n",
    "df = pd.read_csv(DATA_INTERIM_DIR / \"Curie_Data_Chemistry_Parsed.csv\")\n",
    "\n",
    "valid_rows = []\n",
    "invalid_rows = []\n",
    "\n",
    "for idx, row in df.iterrows():\n",
    "    formula = row[\"Material_Name\"]\n",
    "    try:\n",
    "        comp = Composition(formula)\n",
    "        valid_rows.append((idx, comp))\n",
    "    except Exception:\n",
    "        invalid_rows.append(formula)\n",
    "\n",
    "# Build valid dataframe\n",
    "valid_indices = [idx for idx, _ in valid_rows]\n",
    "df_valid = df.loc[valid_indices].copy()\n",
    "\n",
    "# Attach composition column\n",
    "df_valid[\"composition\"] = [comp for _, comp in valid_rows]\n",
    "\n",
    "print(\"Original rows :\", df.shape[0])\n",
    "print(\"Valid formulas:\", df_valid.shape[0])\n",
    "print(\"Invalid formulas removed:\", len(invalid_rows))\n",
    "\n",
    "# Save invalid formulas (VERY IMPORTANT for SI)\n",
    "invalid_path = RESULTS_DIR / \"invalid_formula_entries.csv\"\n",
    "pd.Series(invalid_rows, name=\"Invalid_Material_Name\").to_csv(\n",
    "    invalid_path, index=False\n",
    ")\n",
    "\n",
    "print(\"Invalid formulas saved to:\", invalid_path)\n",
    "\n",
    "# Overwrite df for downstream cells\n",
    "df = df_valid.copy()\n",
    "# ------------------------------------------------\n",
    "# Save valid-formula-only dataset (IMPORTANT)\n",
    "# ------------------------------------------------\n",
    "valid_path = DATA_INTERIM_DIR / \"Curie_Data_Valid_Formulas.csv\"\n",
    "df_valid.to_csv(valid_path, index=False)\n",
    "\n",
    "print(\"Valid-formula dataset saved to:\", valid_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b47e075-ed91-4767-a1cd-3915f0c87cd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# CELL X: DEEP CHEMICAL SANITIZATION (STRICT)\n",
    "# ============================================================\n",
    "\n",
    "import pandas as pd\n",
    "import re\n",
    "from pymatgen.core import Element, Composition\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# 1. Load current \"valid formulas\" dataset\n",
    "# ------------------------------------------------------------\n",
    "df = pd.read_csv(DATA_INTERIM_DIR / \"Curie_Data_Valid_Formulas.csv\")\n",
    "\n",
    "print(\"Input rows:\", df.shape[0])\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# 2. Helper: check if formula is STRICTLY elemental\n",
    "# ------------------------------------------------------------\n",
    "def is_strict_formula(formula):\n",
    "    \"\"\"\n",
    "    Returns (True, None) if formula contains ONLY real elements.\n",
    "    Returns (False, reason) otherwise.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        comp = Composition(formula)\n",
    "    except Exception:\n",
    "        return False, \"Composition parse failed\"\n",
    "\n",
    "    for sym in comp.get_el_amt_dict():\n",
    "        try:\n",
    "            Element(sym)\n",
    "        except Exception:\n",
    "            return False, f\"Non-element token: {sym}\"\n",
    "\n",
    "    return True, None\n",
    "\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# 3. Apply strict validation\n",
    "# ------------------------------------------------------------\n",
    "valid_rows = []\n",
    "invalid_rows = []\n",
    "\n",
    "for _, row in df.iterrows():\n",
    "    formula = row[\"Material_Name\"]\n",
    "    ok, reason = is_strict_formula(formula)\n",
    "    if ok:\n",
    "        valid_rows.append(row)\n",
    "    else:\n",
    "        invalid_rows.append({\n",
    "            \"Material_Name\": formula,\n",
    "            \"Reason\": reason\n",
    "        })\n",
    "\n",
    "df_strict = pd.DataFrame(valid_rows)\n",
    "df_invalid = pd.DataFrame(invalid_rows)\n",
    "\n",
    "print(\"Strictly valid formulas :\", df_strict.shape[0])\n",
    "print(\"Rejected (chemically unsafe):\", df_invalid.shape[0])\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# 4. Save outputs (IMPORTANT)\n",
    "# ------------------------------------------------------------\n",
    "strict_path = DATA_INTERIM_DIR / \"Curie_Data_Strict_Formulas.csv\"\n",
    "invalid_path = RESULTS_DIR / \"invalid_formula_entries_strict.csv\"\n",
    "\n",
    "df_strict.to_csv(strict_path, index=False)\n",
    "df_invalid.to_csv(invalid_path, index=False)\n",
    "\n",
    "print(\"\\nSaved STRICT dataset to:\", strict_path)\n",
    "print(\"Saved rejected formulas to:\", invalid_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec06ff4f-59b2-4858-acce-729352af0de8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# CELL 5: EXTENDED PHYSICS + MATMINER DESCRIPTORS\n",
    "#        (STRICT, FINAL, OVERLAP-SAFE)\n",
    "# ============================================================\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from pymatgen.core import Composition, Element\n",
    "from matminer.featurizers.composition import (\n",
    "    ElementProperty,\n",
    "    Stoichiometry,\n",
    "    ValenceOrbital,\n",
    "    IonProperty,\n",
    "    AtomicOrbitals,\n",
    "    BandCenter\n",
    ")\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# 1. Load STRICTLY CLEANED dataset\n",
    "# ------------------------------------------------------------\n",
    "df = pd.read_csv(DATA_INTERIM_DIR / \"Curie_Data_Strict_Formulas.csv\")\n",
    "print(\"Dataset loaded (strict formulas only):\", df.shape)\n",
    "\n",
    "# Guaranteed safe\n",
    "df[\"composition\"] = df[\"Material_Name\"].apply(Composition)\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# 2. Remove any existing physics columns (RESTART SAFE)\n",
    "# ------------------------------------------------------------\n",
    "PHYS_COLS = [\n",
    "    \"n_elements\", \"composition_entropy\", \"max_atomic_fraction\",\n",
    "    \"frac_3d_elements\", \"frac_RE_elements\",\n",
    "    \"Z_mean_w\", \"Z_std\", \"X_mean_w\", \"X_range\",\n",
    "    \"R_mean_w\", \"R_range\",\n",
    "    \"VEC_mean\", \"VEC_std\",\n",
    "    \"has_Fe\", \"has_Co\", \"has_Mn\", \"has_RE\"\n",
    "]\n",
    "\n",
    "df = df.drop(columns=[c for c in PHYS_COLS if c in df.columns], errors=\"ignore\")\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# 3. PHYSICS-INFORMED HANDCRAFTED FEATURES\n",
    "# ------------------------------------------------------------\n",
    "\n",
    "MAGNETIC_3D = {\"Fe\", \"Co\", \"Ni\", \"Mn\", \"Cr\", \"V\"}\n",
    "RARE_EARTHS = {\n",
    "    \"La\",\"Ce\",\"Pr\",\"Nd\",\"Sm\",\"Eu\",\"Gd\",\"Tb\",\"Dy\",\n",
    "    \"Ho\",\"Er\",\"Tm\",\"Yb\",\"Lu\"\n",
    "}\n",
    "\n",
    "def physics_features(comp):\n",
    "    el_amt = comp.get_el_amt_dict()\n",
    "    total = sum(el_amt.values())\n",
    "\n",
    "    els = [Element(sym) for sym in el_amt]\n",
    "    fracs = {Element(sym): el_amt[sym] / total for sym in el_amt}\n",
    "    frac_vals = np.array(list(fracs.values()))\n",
    "\n",
    "    Z = np.array([e.Z for e in els])\n",
    "    X = np.array([e.X if e.X is not None else np.nan for e in els])\n",
    "    R = np.array([e.atomic_radius if e.atomic_radius is not None else np.nan for e in els])\n",
    "    group = np.array([e.group if e.group is not None else np.nan for e in els])\n",
    "\n",
    "    entropy = -np.sum(frac_vals * np.log(frac_vals))\n",
    "\n",
    "    return pd.Series({\n",
    "        # Chemical complexity\n",
    "        \"n_elements\": len(els),\n",
    "        \"composition_entropy\": entropy,\n",
    "        \"max_atomic_fraction\": frac_vals.max(),\n",
    "\n",
    "        # Magnetic chemistry\n",
    "        \"frac_3d_elements\": sum(fracs[e] for e in fracs if e.symbol in MAGNETIC_3D),\n",
    "        \"frac_RE_elements\": sum(fracs[e] for e in fracs if e.symbol in RARE_EARTHS),\n",
    "\n",
    "        # Atomic statistics (weighted)\n",
    "        \"Z_mean_w\": np.nansum(Z * frac_vals),\n",
    "        \"Z_std\": np.nanstd(Z),\n",
    "        \"X_mean_w\": np.nansum(X * frac_vals),\n",
    "        \"X_range\": np.nanmax(X) - np.nanmin(X),\n",
    "        \"R_mean_w\": np.nansum(R * frac_vals),\n",
    "        \"R_range\": np.nanmax(R) - np.nanmin(R),\n",
    "\n",
    "        # Valence / Slater–Pauling proxies\n",
    "        \"VEC_mean\": np.nansum(group * frac_vals),\n",
    "        \"VEC_std\": np.nanstd(group),\n",
    "\n",
    "        # Flags\n",
    "        \"has_Fe\": int(\"Fe\" in el_amt),\n",
    "        \"has_Co\": int(\"Co\" in el_amt),\n",
    "        \"has_Mn\": int(\"Mn\" in el_amt),\n",
    "        \"has_RE\": int(any(Element(sym).symbol in RARE_EARTHS for sym in el_amt)),\n",
    "    })\n",
    "\n",
    "# SAFE concat (no column overlap issues)\n",
    "df_phys = pd.concat(\n",
    "    [df, df[\"composition\"].apply(physics_features)],\n",
    "    axis=1\n",
    ")\n",
    "\n",
    "print(\"Handcrafted physics-informed features added.\")\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# 4. EXTENDED MATMINER FEATURES\n",
    "# ------------------------------------------------------------\n",
    "\n",
    "ep = ElementProperty.from_preset(\"magpie\")\n",
    "stoich = Stoichiometry()\n",
    "valence = ValenceOrbital(props=[\"avg\", \"frac\"])\n",
    "ion = IonProperty(fast=True)\n",
    "orbitals = AtomicOrbitals()\n",
    "bandcenter = BandCenter()\n",
    "\n",
    "df_feat = ep.featurize_dataframe(df_phys, \"composition\", ignore_errors=True)\n",
    "df_feat = stoich.featurize_dataframe(df_feat, \"composition\", ignore_errors=True)\n",
    "df_feat = valence.featurize_dataframe(df_feat, \"composition\", ignore_errors=True)\n",
    "df_feat = ion.featurize_dataframe(df_feat, \"composition\", ignore_errors=True)\n",
    "df_feat = orbitals.featurize_dataframe(df_feat, \"composition\", ignore_errors=True)\n",
    "df_feat = bandcenter.featurize_dataframe(df_feat, \"composition\", ignore_errors=True)\n",
    "\n",
    "print(\"Extended matminer features generated.\")\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# 5. FINAL ML FEATURE TABLE\n",
    "# ------------------------------------------------------------\n",
    "\n",
    "DROP_COLS = [\n",
    "    \"Material_Name\",\n",
    "    \"elements\",\n",
    "    \"composition\",\n",
    "    \"chemistry_class\"\n",
    "]\n",
    "\n",
    "df_final = df_feat.drop(columns=DROP_COLS, errors=\"ignore\")\n",
    "\n",
    "feature_path = DATA_INTERIM_DIR / \"Curie_Feature_Table_Magpie_Physics.csv\"\n",
    "df_final.to_csv(feature_path, index=False)\n",
    "\n",
    "print(\"FINAL feature table saved to:\", feature_path)\n",
    "print(\"Final feature table shape:\", df_final.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8204d102-9da8-4630-af33-2c318f0fdf98",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# CELL 5B: FEATURE TABLE INSPECTION & SANITY CHECKS (FIXED)\n",
    "# ============================================================\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# 1. Load feature table\n",
    "# ------------------------------------------------------------\n",
    "df = pd.read_csv(DATA_INTERIM_DIR / \"Curie_Feature_Table_Magpie_Physics.csv\")\n",
    "\n",
    "print(\"Feature table shape:\", df.shape)\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# 2. Separate numeric features safely\n",
    "# ------------------------------------------------------------\n",
    "numeric_df = df.select_dtypes(include=[np.number])\n",
    "\n",
    "print(\"Numeric feature count (excluding target):\", numeric_df.shape[1] - 1)\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# 3. Target variable inspection\n",
    "# ------------------------------------------------------------\n",
    "print(\"\\n=== Curie Temperature Statistics ===\")\n",
    "print(df[\"Curie\"].describe())\n",
    "\n",
    "df[\"Curie\"].describe().to_csv(\n",
    "    RESULTS_DIR / \"Tc_target_statistics.csv\"\n",
    ")\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# 4. Missing value check (NUMERIC ONLY)\n",
    "# ------------------------------------------------------------\n",
    "missing_frac = numeric_df.isna().mean().sort_values(ascending=False)\n",
    "missing_frac.to_csv(\n",
    "    RESULTS_DIR / \"feature_missing_fraction.csv\"\n",
    ")\n",
    "\n",
    "print(\"\\nTop numeric features with missing values:\")\n",
    "print(missing_frac[missing_frac > 0].head(10))\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# 5. Low-variance feature check (NUMERIC ONLY)\n",
    "# ------------------------------------------------------------\n",
    "numeric_features_only = numeric_df.drop(columns=[\"Curie\"], errors=\"ignore\")\n",
    "\n",
    "variances = numeric_features_only.var().sort_values()\n",
    "low_var = variances[variances < 1e-6]\n",
    "\n",
    "low_var.to_csv(\n",
    "    RESULTS_DIR / \"low_variance_features.csv\"\n",
    ")\n",
    "\n",
    "print(\"\\nLow-variance numeric features (<1e-6):\", len(low_var))\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# 6. Correlation with Tc (NUMERIC ONLY)\n",
    "# ------------------------------------------------------------\n",
    "corr_with_tc = numeric_features_only.corrwith(df[\"Curie\"]).sort_values()\n",
    "\n",
    "corr_with_tc.to_csv(\n",
    "    RESULTS_DIR / \"feature_correlation_with_Tc.csv\"\n",
    ")\n",
    "\n",
    "print(\"\\nTop + correlated features with Tc:\")\n",
    "print(corr_with_tc.tail(10))\n",
    "\n",
    "print(\"\\nTop − correlated features with Tc:\")\n",
    "print(corr_with_tc.head(10))\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# 7. Physics sanity plots\n",
    "# ------------------------------------------------------------\n",
    "fig, ax = plt.subplots()\n",
    "ax.hist(df[\"Curie\"], bins=50)\n",
    "ax.set_xlabel(\"Curie Temperature (K)\")\n",
    "ax.set_ylabel(\"Count\")\n",
    "ax.set_title(\"Curie Temperature Distribution\")\n",
    "save_figure(fig, \"Tc_distribution_feature_table\")\n",
    "plt.close(fig)\n",
    "\n",
    "KEY_FEATURES = [\n",
    "    \"n_elements\",\n",
    "    \"frac_3d_elements\",\n",
    "    \"frac_RE_elements\",\n",
    "    \"VEC_mean\",\n",
    "    \"composition_entropy\"\n",
    "]\n",
    "\n",
    "for feat in KEY_FEATURES:\n",
    "    if feat in df.columns:\n",
    "        fig, ax = plt.subplots()\n",
    "        ax.scatter(df[feat], df[\"Curie\"], s=5, alpha=0.3)\n",
    "        ax.set_xlabel(feat)\n",
    "        ax.set_ylabel(\"Curie Temperature (K)\")\n",
    "        ax.set_title(f\"Tc vs {feat}\")\n",
    "        save_figure(fig, f\"Tc_vs_{feat}\")\n",
    "        plt.close(fig)\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# 8. Summary\n",
    "# ------------------------------------------------------------\n",
    "summary = {\n",
    "    \"n_samples\": df.shape[0],\n",
    "    \"n_numeric_features\": numeric_features_only.shape[1],\n",
    "    \"n_features_with_nan\": int((missing_frac > 0).sum()),\n",
    "    \"n_low_variance_features\": int(len(low_var))\n",
    "}\n",
    "\n",
    "summary_df = pd.DataFrame([summary])\n",
    "summary_df.to_csv(\n",
    "    RESULTS_DIR / \"feature_table_summary.csv\",\n",
    "    index=False\n",
    ")\n",
    "\n",
    "print(\"\\n=== FEATURE TABLE SUMMARY ===\")\n",
    "print(summary_df)\n",
    "\n",
    "print(\"\\nCELL 5B COMPLETED SUCCESSFULLY.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e4eba23-409a-4e55-9043-c3d1d3af3e65",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# CELL 6: Tc REGRESSION — MULTI-MODEL BENCHMARKING (FINAL)\n",
    "# ============================================================\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import joblib\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "\n",
    "from sklearn.metrics import (\n",
    "    mean_squared_error,\n",
    "    mean_absolute_error,\n",
    "    median_absolute_error,\n",
    "    r2_score\n",
    ")\n",
    "\n",
    "from scipy.stats import pearsonr, spearmanr\n",
    "\n",
    "import xgboost as xgb\n",
    "import lightgbm as lgb\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# 1. Load feature table (numeric only)\n",
    "# ------------------------------------------------------------\n",
    "df = pd.read_csv(DATA_INTERIM_DIR / \"Curie_Feature_Table_Magpie_Physics.csv\")\n",
    "\n",
    "y = df[\"Curie\"].values\n",
    "X = df.drop(columns=[\"Curie\"])\n",
    "\n",
    "# keep numeric features only (critical)\n",
    "X = X.select_dtypes(include=[np.number])\n",
    "\n",
    "print(\"Final ML matrix shape:\", X.shape)\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# 2. Train / test split (REPRODUCIBLE)\n",
    "# ------------------------------------------------------------\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y,\n",
    "    test_size=0.2,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# Save split indices\n",
    "np.savez(\n",
    "    RESULTS_DIR / \"train_test_indices.npz\",\n",
    "    train_idx=X_train.index.values,\n",
    "    test_idx=X_test.index.values\n",
    ")\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# 3. Metric function (ranking-aware)\n",
    "# ------------------------------------------------------------\n",
    "def regression_metrics(y_true, y_pred):\n",
    "    return {\n",
    "        \"RMSE\": np.sqrt(mean_squared_error(y_true, y_pred)),\n",
    "        \"MAE\": mean_absolute_error(y_true, y_pred),\n",
    "        \"MedAE\": median_absolute_error(y_true, y_pred),\n",
    "        \"R2\": r2_score(y_true, y_pred),\n",
    "        \"MAPE_%\": np.mean(\n",
    "            np.abs((y_true - y_pred) / np.clip(y_true, 1e-6, None))\n",
    "        ) * 100,\n",
    "        \"Pearson_r\": pearsonr(y_true, y_pred)[0],\n",
    "        \"Spearman_r\": spearmanr(y_true, y_pred)[0]\n",
    "    }\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# 4. Define models (ALL)\n",
    "# ------------------------------------------------------------\n",
    "models = {\n",
    "    \"Ridge\": Pipeline([\n",
    "        (\"imputer\", SimpleImputer(strategy=\"median\")),\n",
    "        (\"scaler\", StandardScaler()),\n",
    "        (\"model\", Ridge(alpha=1.0))\n",
    "    ]),\n",
    "\n",
    "    \"RandomForest\": Pipeline([\n",
    "        (\"imputer\", SimpleImputer(strategy=\"median\")),\n",
    "        (\"model\", RandomForestRegressor(\n",
    "            n_estimators=500,\n",
    "            random_state=42,\n",
    "            n_jobs=-1\n",
    "        ))\n",
    "    ]),\n",
    "\n",
    "    \"GradientBoosting\": Pipeline([\n",
    "        (\"imputer\", SimpleImputer(strategy=\"median\")),\n",
    "        (\"model\", GradientBoostingRegressor(\n",
    "            random_state=42\n",
    "        ))\n",
    "    ]),\n",
    "\n",
    "    \"XGBoost\": xgb.XGBRegressor(\n",
    "        n_estimators=500,\n",
    "        learning_rate=0.05,\n",
    "        max_depth=6,\n",
    "        subsample=0.8,\n",
    "        colsample_bytree=0.8,\n",
    "        random_state=42,\n",
    "        n_jobs=-1\n",
    "    ),\n",
    "\n",
    "    \"LightGBM\": lgb.LGBMRegressor(\n",
    "        n_estimators=500,\n",
    "        learning_rate=0.05,\n",
    "        random_state=42,\n",
    "        n_jobs=-1\n",
    "    ),\n",
    "\n",
    "    \"MLP\": Pipeline([\n",
    "        (\"imputer\", SimpleImputer(strategy=\"median\")),\n",
    "        (\"scaler\", StandardScaler()),\n",
    "        (\"model\", MLPRegressor(\n",
    "            hidden_layer_sizes=(256,128,64),\n",
    "            activation=\"relu\",\n",
    "            max_iter=1000,\n",
    "            random_state=42\n",
    "        ))\n",
    "    ])\n",
    "}\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# 5. Train, evaluate, save EVERYTHING\n",
    "# ------------------------------------------------------------\n",
    "metrics_all = []\n",
    "\n",
    "for name, model in models.items():\n",
    "    print(f\"\\nTraining {name} ...\")\n",
    "\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "\n",
    "    # Metrics\n",
    "    m = regression_metrics(y_test, y_pred)\n",
    "    m[\"Model\"] = name\n",
    "    metrics_all.append(m)\n",
    "\n",
    "    # Save model\n",
    "    joblib.dump(\n",
    "        model,\n",
    "        RESULTS_DIR / f\"model_{name}.joblib\"\n",
    "    )\n",
    "\n",
    "    # Save predictions\n",
    "    pred_df = pd.DataFrame({\n",
    "        \"y_true\": y_test,\n",
    "        \"y_pred\": y_pred,\n",
    "        \"residual\": y_test - y_pred\n",
    "    })\n",
    "    pred_df.to_csv(\n",
    "        RESULTS_DIR / f\"predictions_{name}.csv\",\n",
    "        index=False\n",
    "    )\n",
    "\n",
    "    # -------- PLOTS --------\n",
    "    # True vs Predicted\n",
    "    fig, ax = plt.subplots()\n",
    "    ax.scatter(y_test, y_pred, s=10, alpha=0.5)\n",
    "    ax.plot(\n",
    "        [y_test.min(), y_test.max()],\n",
    "        [y_test.min(), y_test.max()],\n",
    "        \"--\",\n",
    "        color=\"black\"\n",
    "    )\n",
    "    ax.set_xlabel(\"True Tc (K)\")\n",
    "    ax.set_ylabel(\"Predicted Tc (K)\")\n",
    "    ax.set_title(f\"True vs Predicted Tc — {name}\")\n",
    "    save_figure(fig, f\"Tc_true_vs_pred_{name}\")\n",
    "    plt.close(fig)\n",
    "\n",
    "    # Residuals\n",
    "    fig, ax = plt.subplots()\n",
    "    ax.hist(y_test - y_pred, bins=50)\n",
    "    ax.set_xlabel(\"Residual (K)\")\n",
    "    ax.set_ylabel(\"Count\")\n",
    "    ax.set_title(f\"Residual Distribution — {name}\")\n",
    "    save_figure(fig, f\"Tc_residuals_{name}\")\n",
    "    plt.close(fig)\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# 6. Consolidated metrics table\n",
    "# ------------------------------------------------------------\n",
    "metrics_df = pd.DataFrame(metrics_all).set_index(\"Model\")\n",
    "metrics_df = metrics_df.sort_values(\"RMSE\")\n",
    "\n",
    "metrics_df.to_csv(\n",
    "    RESULTS_DIR / \"regression_metrics_all_models.csv\"\n",
    ")\n",
    "\n",
    "print(\"\\n=== REGRESSION BENCHMARK RESULTS ===\")\n",
    "print(metrics_df)\n",
    "\n",
    "print(\"\\nSaved metrics to:\",\n",
    "      RESULTS_DIR / \"regression_metrics_all_models.csv\")\n",
    "\n",
    "print(\"\\nCELL 6 COMPLETED SUCCESSFULLY.\")\n",
    "# ------------------------------------------------------------\n",
    "# 7. RADAR (SPIDER) PLOT — MODEL PERFORMANCE COMPARISON\n",
    "# ------------------------------------------------------------\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "# ---- Metrics to include in radar plot ----\n",
    "# NOTE: RMSE, MAE, MedAE, MAPE should be minimized → invert later\n",
    "RADAR_METRICS = [\n",
    "    \"RMSE\",\n",
    "    \"MAE\",\n",
    "    \"MedAE\",\n",
    "    \"R2\",\n",
    "    \"Pearson_r\",\n",
    "    \"Spearman_r\"\n",
    "]\n",
    "\n",
    "radar_df = metrics_df[RADAR_METRICS].copy()\n",
    "\n",
    "# ---- Normalize metrics to [0,1] ----\n",
    "# Higher is better for radar plot\n",
    "radar_norm = pd.DataFrame(index=radar_df.index)\n",
    "\n",
    "for col in radar_df.columns:\n",
    "    if col in [\"RMSE\", \"MAE\", \"MedAE\"]:\n",
    "        # lower is better → invert\n",
    "        radar_norm[col] = 1 - (\n",
    "            (radar_df[col] - radar_df[col].min()) /\n",
    "            (radar_df[col].max() - radar_df[col].min())\n",
    "        )\n",
    "    else:\n",
    "        # higher is better\n",
    "        radar_norm[col] = (\n",
    "            (radar_df[col] - radar_df[col].min()) /\n",
    "            (radar_df[col].max() - radar_df[col].min())\n",
    "        )\n",
    "\n",
    "# Save normalized radar table (SI-ready)\n",
    "radar_norm.to_csv(\n",
    "    RESULTS_DIR / \"radar_metrics_normalized.csv\"\n",
    ")\n",
    "\n",
    "# ---- Radar plot setup ----\n",
    "labels = radar_norm.columns.tolist()\n",
    "num_vars = len(labels)\n",
    "\n",
    "angles = np.linspace(0, 2 * np.pi, num_vars, endpoint=False).tolist()\n",
    "angles += angles[:1]  # close loop\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(8, 8), subplot_kw=dict(polar=True))\n",
    "\n",
    "for model in radar_norm.index:\n",
    "    values = radar_norm.loc[model].tolist()\n",
    "    values += values[:1]\n",
    "\n",
    "    ax.plot(angles, values, linewidth=2, label=model)\n",
    "    ax.fill(angles, values, alpha=0.10)\n",
    "\n",
    "# ---- Formatting ----\n",
    "ax.set_theta_offset(np.pi / 2)\n",
    "ax.set_theta_direction(-1)\n",
    "\n",
    "ax.set_thetagrids(\n",
    "    np.degrees(angles[:-1]),\n",
    "    labels\n",
    ")\n",
    "\n",
    "ax.set_ylim(0, 1)\n",
    "ax.set_title(\"Model Performance Comparison (Radar Plot)\", pad=20)\n",
    "ax.legend(loc=\"upper right\", bbox_to_anchor=(1.35, 1.15))\n",
    "\n",
    "# ---- Save figure ----\n",
    "save_figure(fig, \"Tc_model_comparison_radar\")\n",
    "plt.close(fig)\n",
    "\n",
    "print(\"Radar plot saved: Tc_model_comparison_radar (PNG + PDF)\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "261891cb-d1fd-452c-9bb8-cab06051b46a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np, pandas as pd, shap, joblib, matplotlib.pyplot as plt\n",
    "\n",
    "# ---- Paths\n",
    "OUT = RESULTS_DIR / \"shap\" / \"RF\"\n",
    "OUT.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# ---- Data\n",
    "df = pd.read_csv(DATA_INTERIM_DIR / \"Curie_Feature_Table_Magpie_Physics.csv\")\n",
    "X = df.drop(columns=[\"Curie\"]).select_dtypes(include=[np.number])\n",
    "feature_names = X.columns.tolist()\n",
    "\n",
    "# ---- Subsample for speed (reproducible)\n",
    "X_shap = X.sample(800, random_state=42)\n",
    "\n",
    "# ---- Model\n",
    "rf = joblib.load(RESULTS_DIR / \"model_RandomForest.joblib\")\n",
    "if hasattr(rf, \"named_steps\"):\n",
    "    rf = rf.named_steps[\"model\"]\n",
    "\n",
    "# ---- SHAP\n",
    "explainer = shap.TreeExplainer(rf)\n",
    "shap_vals = explainer.shap_values(X_shap)\n",
    "\n",
    "mean_abs = np.abs(shap_vals).mean(axis=0)\n",
    "rank = (pd.DataFrame({\"feature\": feature_names, \"mean_abs_shap\": mean_abs})\n",
    "        .sort_values(\"mean_abs_shap\", ascending=False))\n",
    "rank.to_csv(OUT / \"shap_mean_abs.csv\", index=False)\n",
    "\n",
    "# ---- Plots\n",
    "fig = plt.figure()\n",
    "shap.summary_plot(shap_vals, X_shap, max_display=25, show=False)\n",
    "save_figure(fig, \"RF_shap_summary\", outdir=OUT); plt.close(fig)\n",
    "\n",
    "fig = plt.figure()\n",
    "shap.summary_plot(shap_vals, X_shap, plot_type=\"bar\", max_display=25, show=False)\n",
    "save_figure(fig, \"RF_shap_bar\", outdir=OUT); plt.close(fig)\n",
    "\n",
    "print(\"RF SHAP done.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c34375d-18f2-4ea1-8ae6-86e0afe7ca0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import shap\n",
    "import joblib\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "\n",
    "# -------------------------------\n",
    "# Paths\n",
    "# -------------------------------\n",
    "OUT = RESULTS_DIR / \"shap\" / \"RF\"\n",
    "OUT.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# -------------------------------\n",
    "# Load data\n",
    "# -------------------------------\n",
    "df = pd.read_csv(DATA_INTERIM_DIR / \"Curie_Feature_Table_Magpie_Physics.csv\")\n",
    "X = df.drop(columns=[\"Curie\"]).select_dtypes(include=[np.number])\n",
    "feature_names = X.columns.tolist()\n",
    "\n",
    "# Subsample for SHAP (speed + reproducibility)\n",
    "X_shap = X.sample(800, random_state=42)\n",
    "\n",
    "# -------------------------------\n",
    "# Load model\n",
    "# -------------------------------\n",
    "rf = joblib.load(RESULTS_DIR / \"model_RandomForest.joblib\")\n",
    "if hasattr(rf, \"named_steps\"):\n",
    "    rf = rf.named_steps[\"model\"]\n",
    "\n",
    "# -------------------------------\n",
    "# SHAP computation\n",
    "# -------------------------------\n",
    "print(\"Running SHAP for RandomForest...\")\n",
    "explainer = shap.TreeExplainer(rf)\n",
    "shap_vals = explainer.shap_values(X_shap)\n",
    "\n",
    "# -------------------------------\n",
    "# Save mean |SHAP|\n",
    "# -------------------------------\n",
    "mean_abs = np.abs(shap_vals).mean(axis=0)\n",
    "rank = pd.DataFrame({\n",
    "    \"feature\": feature_names,\n",
    "    \"mean_abs_shap\": mean_abs\n",
    "}).sort_values(\"mean_abs_shap\", ascending=False)\n",
    "\n",
    "rank.to_csv(OUT / \"shap_mean_abs.csv\", index=False)\n",
    "\n",
    "# -------------------------------\n",
    "# Plots\n",
    "# -------------------------------\n",
    "fig = plt.figure()\n",
    "shap.summary_plot(shap_vals, X_shap, max_display=25, show=False)\n",
    "fig.savefig(OUT / \"RF_shap_summary.png\", dpi=300, bbox_inches=\"tight\")\n",
    "fig.savefig(OUT / \"RF_shap_summary.pdf\", bbox_inches=\"tight\")\n",
    "plt.close(fig)\n",
    "\n",
    "fig = plt.figure()\n",
    "shap.summary_plot(shap_vals, X_shap, plot_type=\"bar\", max_display=25, show=False)\n",
    "fig.savefig(OUT / \"RF_shap_bar.png\", dpi=300, bbox_inches=\"tight\")\n",
    "fig.savefig(OUT / \"RF_shap_bar.pdf\", bbox_inches=\"tight\")\n",
    "plt.close(fig)\n",
    "\n",
    "print(\"RF SHAP completed.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06234720-b861-4752-8666-60bf46cbd911",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import shap\n",
    "import joblib\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "\n",
    "OUT = RESULTS_DIR / \"shap\" / \"LGBM\"\n",
    "OUT.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "df = pd.read_csv(DATA_INTERIM_DIR / \"Curie_Feature_Table_Magpie_Physics.csv\")\n",
    "X = df.drop(columns=[\"Curie\"]).select_dtypes(include=[np.number])\n",
    "feature_names = X.columns.tolist()\n",
    "\n",
    "X_shap = X.sample(800, random_state=42)\n",
    "\n",
    "lgbm = joblib.load(RESULTS_DIR / \"model_LightGBM.joblib\")\n",
    "\n",
    "print(\"Running SHAP for LightGBM...\")\n",
    "explainer = shap.TreeExplainer(lgbm)\n",
    "shap_vals = explainer.shap_values(X_shap)\n",
    "\n",
    "mean_abs = np.abs(shap_vals).mean(axis=0)\n",
    "rank = pd.DataFrame({\n",
    "    \"feature\": feature_names,\n",
    "    \"mean_abs_shap\": mean_abs\n",
    "}).sort_values(\"mean_abs_shap\", ascending=False)\n",
    "\n",
    "rank.to_csv(OUT / \"shap_mean_abs.csv\", index=False)\n",
    "\n",
    "fig = plt.figure()\n",
    "shap.summary_plot(shap_vals, X_shap, max_display=25, show=False)\n",
    "fig.savefig(OUT / \"LGBM_shap_summary.png\", dpi=300, bbox_inches=\"tight\")\n",
    "fig.savefig(OUT / \"LGBM_shap_summary.pdf\", bbox_inches=\"tight\")\n",
    "plt.close(fig)\n",
    "\n",
    "fig = plt.figure()\n",
    "shap.summary_plot(shap_vals, X_shap, plot_type=\"bar\", max_display=25, show=False)\n",
    "fig.savefig(OUT / \"LGBM_shap_bar.png\", dpi=300, bbox_inches=\"tight\")\n",
    "fig.savefig(OUT / \"LGBM_shap_bar.pdf\", bbox_inches=\"tight\")\n",
    "plt.close(fig)\n",
    "\n",
    "print(\"LGBM SHAP completed.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c050cba-7aee-41be-8c9c-683b9700c41e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import shap\n",
    "import joblib\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "\n",
    "OUT = RESULTS_DIR / \"shap\" / \"XGB\"\n",
    "OUT.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "df = pd.read_csv(DATA_INTERIM_DIR / \"Curie_Feature_Table_Magpie_Physics.csv\")\n",
    "X = df.drop(columns=[\"Curie\"]).select_dtypes(include=[np.number])\n",
    "feature_names = X.columns.tolist()\n",
    "\n",
    "X_shap = X.sample(800, random_state=42)\n",
    "\n",
    "xgb_model = joblib.load(RESULTS_DIR / \"model_XGBoost.joblib\")\n",
    "\n",
    "def xgb_predict(Xi):\n",
    "    return xgb_model.predict(Xi)\n",
    "\n",
    "print(\"Running SHAP for XGBoost (callable mode)...\")\n",
    "\n",
    "masker = shap.maskers.Independent(X_shap)\n",
    "explainer = shap.Explainer(xgb_predict, masker)\n",
    "\n",
    "shap_exp = explainer(X_shap)\n",
    "shap_vals = shap_exp.values\n",
    "\n",
    "mean_abs = np.abs(shap_vals).mean(axis=0)\n",
    "rank = pd.DataFrame({\n",
    "    \"feature\": feature_names,\n",
    "    \"mean_abs_shap\": mean_abs\n",
    "}).sort_values(\"mean_abs_shap\", ascending=False)\n",
    "\n",
    "rank.to_csv(OUT / \"shap_mean_abs.csv\", index=False)\n",
    "\n",
    "fig = plt.figure()\n",
    "shap.summary_plot(shap_vals, X_shap, max_display=25, show=False)\n",
    "fig.savefig(OUT / \"XGB_shap_summary.png\", dpi=300, bbox_inches=\"tight\")\n",
    "fig.savefig(OUT / \"XGB_shap_summary.pdf\", bbox_inches=\"tight\")\n",
    "plt.close(fig)\n",
    "\n",
    "fig = plt.figure()\n",
    "shap.summary_plot(shap_vals, X_shap, plot_type=\"bar\", max_display=25, show=False)\n",
    "fig.savefig(OUT / \"XGB_shap_bar.png\", dpi=300, bbox_inches=\"tight\")\n",
    "fig.savefig(OUT / \"XGB_shap_bar.pdf\", bbox_inches=\"tight\")\n",
    "plt.close(fig)\n",
    "\n",
    "print(\"XGB SHAP completed.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa4732b8-37a2-45ce-81ee-f3070fcdc307",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "BASE = RESULTS_DIR / \"shap\"\n",
    "TABLE_OUT = RESULTS_DIR / \"tables\"\n",
    "FIG_OUT = RESULTS_DIR / \"figures\"\n",
    "\n",
    "models = [\"RF\", \"LGBM\", \"XGB\"]\n",
    "\n",
    "tables = []\n",
    "for m in models:\n",
    "    t = pd.read_csv(BASE / m / \"shap_mean_abs.csv\").head(10)\n",
    "    t[\"Model\"] = m\n",
    "    tables.append(t)\n",
    "\n",
    "shap_all = pd.concat(tables, ignore_index=True)\n",
    "shap_all.to_csv(TABLE_OUT / \"shap_top10_all_models.csv\", index=False)\n",
    "\n",
    "# Consensus\n",
    "consensus = (\n",
    "    shap_all\n",
    "    .pivot_table(index=\"feature\", values=\"mean_abs_shap\", aggfunc=\"mean\")\n",
    "    .sort_values(\"mean_abs_shap\", ascending=False)\n",
    ")\n",
    "consensus.to_csv(TABLE_OUT / \"shap_consensus.csv\")\n",
    "\n",
    "# Radar plot\n",
    "rad = shap_all.pivot_table(\n",
    "    index=\"Model\", columns=\"feature\", values=\"mean_abs_shap\"\n",
    ").fillna(0.0)\n",
    "\n",
    "rad = rad.div(rad.max())\n",
    "\n",
    "labels = rad.columns.tolist()\n",
    "angles = np.linspace(0, 2*np.pi, len(labels), endpoint=False).tolist()\n",
    "angles += angles[:1]\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(8, 8), subplot_kw=dict(polar=True))\n",
    "for m in rad.index:\n",
    "    vals = rad.loc[m].tolist()\n",
    "    vals += vals[:1]\n",
    "    ax.plot(angles, vals, linewidth=2, label=m)\n",
    "    ax.fill(angles, vals, alpha=0.15)\n",
    "\n",
    "ax.set_thetagrids(np.degrees(angles[:-1]), labels)\n",
    "ax.set_title(\"SHAP Feature Importance — Model Comparison (Radar)\", pad=20)\n",
    "ax.legend(loc=\"upper right\", bbox_to_anchor=(1.35, 1.15))\n",
    "\n",
    "fig.savefig(FIG_OUT / \"shap_radar_comparison.png\", dpi=300, bbox_inches=\"tight\")\n",
    "fig.savefig(FIG_OUT / \"shap_radar_comparison.pdf\", bbox_inches=\"tight\")\n",
    "plt.close(fig)\n",
    "\n",
    "print(\"Consensus SHAP + radar plot saved.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ff95a79-d2a0-43de-bdb3-448d2aac63f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_NAME = \"XGBoost\"\n",
    "\n",
    "import numpy as np, pandas as pd, matplotlib.pyplot as plt\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# Directories\n",
    "# ------------------------------------------------------------\n",
    "BASE_DIR = RESULTS_DIR / \"error_analysis\" / MODEL_NAME\n",
    "TABLE_DIR = BASE_DIR / \"tables\"\n",
    "FIG_DIR = BASE_DIR / \"figures\"\n",
    "TABLE_DIR.mkdir(parents=True, exist_ok=True)\n",
    "FIG_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# Load data\n",
    "# ------------------------------------------------------------\n",
    "df = pd.read_csv(DATA_INTERIM_DIR / \"Curie_Feature_Table_Magpie_Physics.csv\")\n",
    "\n",
    "# Reconstruct chemistry_class\n",
    "def classify_chemistry(row):\n",
    "    if row[\"frac_RE_elements\"] > 0.2 and row[\"frac_3d_elements\"] > 0.2:\n",
    "        return \"RE–TM hybrid\"\n",
    "    elif row[\"frac_RE_elements\"] > 0.2:\n",
    "        return \"Rare-earth based\"\n",
    "    elif row[\"frac_3d_elements\"] > 0.2:\n",
    "        return \"3d-transition-metal\"\n",
    "    else:\n",
    "        return \"Other\"\n",
    "\n",
    "df[\"chemistry_class\"] = df.apply(classify_chemistry, axis=1)\n",
    "\n",
    "# Load split + predictions\n",
    "idx = np.load(RESULTS_DIR / \"train_test_indices.npz\", allow_pickle=True)\n",
    "test_idx = idx[\"test_idx\"]\n",
    "pred = pd.read_csv(RESULTS_DIR / \"predictions_XGBoost.csv\")\n",
    "\n",
    "df_test = df.loc[test_idx].copy()\n",
    "df_test[\"Tc_true\"] = pred[\"y_true\"].values\n",
    "df_test[\"Tc_pred\"] = pred[\"y_pred\"].values\n",
    "df_test[\"residual\"] = df_test[\"Tc_true\"] - df_test[\"Tc_pred\"]\n",
    "df_test[\"abs_error\"] = np.abs(df_test[\"residual\"])\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# Global residuals\n",
    "# ------------------------------------------------------------\n",
    "fig, ax = plt.subplots()\n",
    "ax.hist(df_test[\"residual\"], bins=60)\n",
    "ax.set_xlabel(\"Residual (K)\")\n",
    "ax.set_ylabel(\"Count\")\n",
    "ax.set_title(\"Residual Distribution — XGBoost\")\n",
    "fig.savefig(FIG_DIR / \"residual_distribution.png\", dpi=300, bbox_inches=\"tight\")\n",
    "fig.savefig(FIG_DIR / \"residual_distribution.pdf\", bbox_inches=\"tight\")\n",
    "plt.close(fig)\n",
    "\n",
    "df_test[\"abs_error\"].describe().to_csv(TABLE_DIR / \"global_error_statistics.csv\")\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# Chemistry-resolved errors\n",
    "# ------------------------------------------------------------\n",
    "chem_err = (\n",
    "    df_test.groupby(\"chemistry_class\")[\"abs_error\"]\n",
    "    .agg([\"mean\", \"median\", \"std\", \"count\"])\n",
    ")\n",
    "chem_err.to_csv(TABLE_DIR / \"error_by_chemistry_class.csv\")\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# Physics-informed failure probes\n",
    "# ------------------------------------------------------------\n",
    "df_test.groupby(df_test[\"frac_RE_elements\"] > 0.2)[\"abs_error\"].mean().to_csv(\n",
    "    TABLE_DIR / \"error_RE_rich_vs_not.csv\"\n",
    ")\n",
    "\n",
    "df_test.groupby(df_test[\"frac_3d_elements\"] > 0.3)[\"abs_error\"].mean().to_csv(\n",
    "    TABLE_DIR / \"error_3d_rich_vs_not.csv\"\n",
    ")\n",
    "\n",
    "pd.qcut(\n",
    "    df_test[\"composition_entropy\"], 3,\n",
    "    labels=[\"Low\", \"Medium\", \"High\"]\n",
    ").to_frame(\"entropy_bin\").join(df_test).groupby(\n",
    "    \"entropy_bin\"\n",
    ")[\"abs_error\"].mean().to_csv(\n",
    "    TABLE_DIR / \"error_by_entropy_regime.csv\"\n",
    ")\n",
    "\n",
    "print(f\"CELL 7A COMPLETED: {MODEL_NAME}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f0b4976-d13a-491d-9e0b-2fb9107fafbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_NAME = \"RandomForest\"\n",
    "\n",
    "import numpy as np, pandas as pd, matplotlib.pyplot as plt\n",
    "\n",
    "BASE_DIR = RESULTS_DIR / \"error_analysis\" / MODEL_NAME\n",
    "TABLE_DIR = BASE_DIR / \"tables\"\n",
    "FIG_DIR = BASE_DIR / \"figures\"\n",
    "TABLE_DIR.mkdir(parents=True, exist_ok=True)\n",
    "FIG_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "df = pd.read_csv(DATA_INTERIM_DIR / \"Curie_Feature_Table_Magpie_Physics.csv\")\n",
    "\n",
    "def classify_chemistry(row):\n",
    "    if row[\"frac_RE_elements\"] > 0.2 and row[\"frac_3d_elements\"] > 0.2:\n",
    "        return \"RE–TM hybrid\"\n",
    "    elif row[\"frac_RE_elements\"] > 0.2:\n",
    "        return \"Rare-earth based\"\n",
    "    elif row[\"frac_3d_elements\"] > 0.2:\n",
    "        return \"3d-transition-metal\"\n",
    "    else:\n",
    "        return \"Other\"\n",
    "\n",
    "df[\"chemistry_class\"] = df.apply(classify_chemistry, axis=1)\n",
    "\n",
    "idx = np.load(RESULTS_DIR / \"train_test_indices.npz\", allow_pickle=True)\n",
    "test_idx = idx[\"test_idx\"]\n",
    "pred = pd.read_csv(RESULTS_DIR / \"predictions_RandomForest.csv\")\n",
    "\n",
    "df_test = df.loc[test_idx].copy()\n",
    "df_test[\"Tc_true\"] = pred[\"y_true\"].values\n",
    "df_test[\"Tc_pred\"] = pred[\"y_pred\"].values\n",
    "df_test[\"residual\"] = df_test[\"Tc_true\"] - df_test[\"Tc_pred\"]\n",
    "df_test[\"abs_error\"] = np.abs(df_test[\"residual\"])\n",
    "\n",
    "df_test[\"abs_error\"].describe().to_csv(TABLE_DIR / \"global_error_statistics.csv\")\n",
    "\n",
    "chem_err = df_test.groupby(\"chemistry_class\")[\"abs_error\"].mean()\n",
    "chem_err.to_csv(TABLE_DIR / \"error_by_chemistry_class.csv\")\n",
    "\n",
    "print(f\"CELL 7B COMPLETED: {MODEL_NAME}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96f7d402-f622-499c-a290-cec6947312c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_NAME = \"LightGBM\"\n",
    "\n",
    "import numpy as np, pandas as pd, matplotlib.pyplot as plt\n",
    "\n",
    "BASE_DIR = RESULTS_DIR / \"error_analysis\" / MODEL_NAME\n",
    "TABLE_DIR = BASE_DIR / \"tables\"\n",
    "FIG_DIR = BASE_DIR / \"figures\"\n",
    "TABLE_DIR.mkdir(parents=True, exist_ok=True)\n",
    "FIG_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "df = pd.read_csv(DATA_INTERIM_DIR / \"Curie_Feature_Table_Magpie_Physics.csv\")\n",
    "\n",
    "def classify_chemistry(row):\n",
    "    if row[\"frac_RE_elements\"] > 0.2 and row[\"frac_3d_elements\"] > 0.2:\n",
    "        return \"RE–TM hybrid\"\n",
    "    elif row[\"frac_RE_elements\"] > 0.2:\n",
    "        return \"Rare-earth based\"\n",
    "    elif row[\"frac_3d_elements\"] > 0.2:\n",
    "        return \"3d-transition-metal\"\n",
    "    else:\n",
    "        return \"Other\"\n",
    "\n",
    "df[\"chemistry_class\"] = df.apply(classify_chemistry, axis=1)\n",
    "\n",
    "idx = np.load(RESULTS_DIR / \"train_test_indices.npz\", allow_pickle=True)\n",
    "test_idx = idx[\"test_idx\"]\n",
    "pred = pd.read_csv(RESULTS_DIR / \"predictions_LightGBM.csv\")\n",
    "\n",
    "df_test = df.loc[test_idx].copy()\n",
    "df_test[\"Tc_true\"] = pred[\"y_true\"].values\n",
    "df_test[\"Tc_pred\"] = pred[\"y_pred\"].values\n",
    "df_test[\"residual\"] = df_test[\"Tc_true\"] - df_test[\"Tc_pred\"]\n",
    "df_test[\"abs_error\"] = np.abs(df_test[\"residual\"])\n",
    "\n",
    "df_test[\"abs_error\"].describe().to_csv(TABLE_DIR / \"global_error_statistics.csv\")\n",
    "\n",
    "chem_err = df_test.groupby(\"chemistry_class\")[\"abs_error\"].mean()\n",
    "chem_err.to_csv(TABLE_DIR / \"error_by_chemistry_class.csv\")\n",
    "\n",
    "print(f\"CELL 7C COMPLETED: {MODEL_NAME}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "819db5bc-b1cc-40cb-9844-192aa13ed16a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# 0. Paths\n",
    "# ------------------------------------------------------------\n",
    "BASE_ERR = RESULTS_DIR / \"error_analysis\"\n",
    "TABLE_DIR = BASE_ERR / \"tables_cross_model\"\n",
    "FIG_DIR = BASE_ERR / \"figures_cross_model\"\n",
    "\n",
    "TABLE_DIR.mkdir(parents=True, exist_ok=True)\n",
    "FIG_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "MODELS = [\"XGBoost\", \"RandomForest\", \"LightGBM\"]\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# 1. LOAD GLOBAL ERROR STATISTICS (ROBUST)\n",
    "# ------------------------------------------------------------\n",
    "global_stats = []\n",
    "\n",
    "for m in MODELS:\n",
    "    stats = pd.read_csv(\n",
    "        BASE_ERR / m / \"tables\" / \"global_error_statistics.csv\",\n",
    "        index_col=0\n",
    "    )\n",
    "\n",
    "    # stats is a single-column DataFrame from Series.describe()\n",
    "    series = stats.iloc[:, 0]\n",
    "\n",
    "    row = {\n",
    "        \"Model\": m,\n",
    "        \"MAE_mean\": series.loc[\"mean\"],\n",
    "        \"MAE_median\": series.loc[\"50%\"],\n",
    "        \"MAE_std\": series.loc[\"std\"],\n",
    "        \"MAE_90p\": series.quantile(0.90)\n",
    "    }\n",
    "\n",
    "    global_stats.append(row)\n",
    "\n",
    "global_df = pd.DataFrame(global_stats).set_index(\"Model\")\n",
    "global_df.to_csv(TABLE_DIR / \"global_error_comparison.csv\")\n",
    "\n",
    "print(\"Global error comparison:\")\n",
    "print(global_df)\n",
    "\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# 2. CHEMISTRY-RESOLVED ERROR COMPARISON\n",
    "# ------------------------------------------------------------\n",
    "chem_tables = []\n",
    "\n",
    "for m in MODELS:\n",
    "    chem = pd.read_csv(\n",
    "        BASE_ERR / m / \"tables\" / \"error_by_chemistry_class.csv\",\n",
    "        index_col=0\n",
    "    )\n",
    "    chem[\"Model\"] = m\n",
    "    chem_tables.append(chem.reset_index())\n",
    "\n",
    "chem_df = pd.concat(chem_tables)\n",
    "chem_df.to_csv(TABLE_DIR / \"error_by_chemistry_cross_model.csv\", index=False)\n",
    "\n",
    "# Pivot for comparison table\n",
    "chem_pivot = chem_df.pivot_table(\n",
    "    index=\"chemistry_class\",\n",
    "    columns=\"Model\",\n",
    "    values=\"mean\"\n",
    ")\n",
    "chem_pivot.to_csv(TABLE_DIR / \"error_by_chemistry_pivot.csv\")\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# 3. ERROR REGIME COMPARISON (Tc REGIMES)\n",
    "# ------------------------------------------------------------\n",
    "regime_tables = []\n",
    "\n",
    "for m in MODELS:\n",
    "    path = BASE_ERR / m / \"tables\" / \"error_by_Tc_regime.csv\"\n",
    "    if path.exists():\n",
    "        reg = pd.read_csv(path)\n",
    "        reg[\"Model\"] = m\n",
    "        regime_tables.append(reg)\n",
    "\n",
    "if regime_tables:\n",
    "    regime_df = pd.concat(regime_tables)\n",
    "    regime_df.to_csv(TABLE_DIR / \"error_by_Tc_regime_cross_model.csv\", index=False)\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# 4. RADAR (SPIDER) PLOT — GLOBAL ERROR METRICS\n",
    "# ------------------------------------------------------------\n",
    "# Normalize: lower error = better → invert scale\n",
    "radar_df = global_df.copy()\n",
    "\n",
    "for col in radar_df.columns:\n",
    "    radar_df[col] = 1 - (\n",
    "        (radar_df[col] - radar_df[col].min()) /\n",
    "        (radar_df[col].max() - radar_df[col].min())\n",
    "    )\n",
    "\n",
    "labels = radar_df.columns.tolist()\n",
    "angles = np.linspace(0, 2 * np.pi, len(labels), endpoint=False).tolist()\n",
    "angles += angles[:1]\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(8, 8), subplot_kw=dict(polar=True))\n",
    "\n",
    "for model in radar_df.index:\n",
    "    values = radar_df.loc[model].tolist()\n",
    "    values += values[:1]\n",
    "    ax.plot(angles, values, linewidth=2, label=model)\n",
    "    ax.fill(angles, values, alpha=0.15)\n",
    "\n",
    "ax.set_thetagrids(np.degrees(angles[:-1]), labels)\n",
    "ax.set_ylim(0, 1)\n",
    "ax.set_title(\"Cross-Model Error Performance Comparison (Radar)\", pad=20)\n",
    "ax.legend(loc=\"upper right\", bbox_to_anchor=(1.35, 1.15))\n",
    "\n",
    "fig.savefig(FIG_DIR / \"error_radar_global.png\", dpi=300, bbox_inches=\"tight\")\n",
    "fig.savefig(FIG_DIR / \"error_radar_global.pdf\", bbox_inches=\"tight\")\n",
    "plt.close(fig)\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# 5. RADAR — CHEMISTRY-SPECIFIC PERFORMANCE (OPTIONAL BUT VALUABLE)\n",
    "# ------------------------------------------------------------\n",
    "chem_norm = chem_pivot.copy()\n",
    "\n",
    "for col in chem_norm.columns:\n",
    "    chem_norm[col] = 1 - (\n",
    "        (chem_norm[col] - chem_norm[col].min()) /\n",
    "        (chem_norm[col].max() - chem_norm[col].min())\n",
    "    )\n",
    "\n",
    "labels = chem_norm.index.tolist()\n",
    "angles = np.linspace(0, 2 * np.pi, len(labels), endpoint=False).tolist()\n",
    "angles += angles[:1]\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(8, 8), subplot_kw=dict(polar=True))\n",
    "\n",
    "for model in chem_norm.columns:\n",
    "    vals = chem_norm[model].tolist()\n",
    "    vals += vals[:1]\n",
    "    ax.plot(angles, vals, linewidth=2, label=model)\n",
    "    ax.fill(angles, vals, alpha=0.15)\n",
    "\n",
    "ax.set_thetagrids(np.degrees(angles[:-1]), labels)\n",
    "ax.set_ylim(0, 1)\n",
    "ax.set_title(\"Model Robustness Across Chemistry Classes (Radar)\", pad=20)\n",
    "ax.legend(loc=\"upper right\", bbox_to_anchor=(1.35, 1.15))\n",
    "\n",
    "fig.savefig(FIG_DIR / \"error_radar_chemistry.png\", dpi=300, bbox_inches=\"tight\")\n",
    "fig.savefig(FIG_DIR / \"error_radar_chemistry.pdf\", bbox_inches=\"tight\")\n",
    "plt.close(fig)\n",
    "\n",
    "print(\"\\nCELL 7D COMPLETED SUCCESSFULLY.\")\n",
    "print(\"Cross-model comparison tables & radar plots saved to:\")\n",
    "print(BASE_ERR)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69a81c0c-0045-48af-ac0e-be2ff068114d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from itertools import combinations\n",
    "from pymatgen.core import Composition\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# 0. Paths\n",
    "# ------------------------------------------------------------\n",
    "INV_DIR = RESULTS_DIR / \"inverse_design\"\n",
    "TABLE_DIR = INV_DIR / \"tables\"\n",
    "INV_DIR.mkdir(exist_ok=True, parents=True)\n",
    "TABLE_DIR.mkdir(exist_ok=True, parents=True)\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# 1. ELEMENT POOLS (DATA-INFORMED)\n",
    "# ------------------------------------------------------------\n",
    "TM_3D = [\"Fe\", \"Co\", \"Mn\", \"Ni\", \"Cr\", \"V\"]\n",
    "RARE_EARTHS = [\"Gd\", \"Tb\", \"Dy\", \"Ho\", \"Er\"]\n",
    "MAIN_GROUP = [\"Al\", \"Si\", \"Ge\", \"Ga\", \"Sn\"]\n",
    "\n",
    "ELEMENT_POOL = TM_3D + RARE_EARTHS + MAIN_GROUP\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# 2. STOICHIOMETRIC PATTERNS\n",
    "# ------------------------------------------------------------\n",
    "STOICH_PATTERNS = {\n",
    "    2: [(0.5, 0.5)],\n",
    "    3: [(0.33, 0.33, 0.34)],\n",
    "    4: [(0.25, 0.25, 0.25, 0.25)]\n",
    "}\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# 3. PHYSICS-BASED CONSTRAINTS (FIXED)\n",
    "# ------------------------------------------------------------\n",
    "def physics_constraints(comp: Composition):\n",
    "    comp_frac = comp.fractional_composition\n",
    "    fracs = comp_frac.get_el_amt_dict()\n",
    "    els = list(fracs.keys())\n",
    "\n",
    "    frac_3d = sum(fracs.get(e, 0) for e in TM_3D)\n",
    "    frac_re = sum(fracs.get(e, 0) for e in RARE_EARTHS)\n",
    "\n",
    "    entropy = -sum(v * np.log(v) for v in fracs.values())\n",
    "\n",
    "    if frac_3d < 0.30:\n",
    "        return False\n",
    "    if frac_re > 0.40:\n",
    "        return False\n",
    "    if entropy > 1.35:\n",
    "        return False\n",
    "    if len(els) > 4:\n",
    "        return False\n",
    "\n",
    "    return True\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# 4. GENERATE CANDIDATES\n",
    "# ------------------------------------------------------------\n",
    "candidates = []\n",
    "\n",
    "for n_elem, patterns in STOICH_PATTERNS.items():\n",
    "    for elems in combinations(ELEMENT_POOL, n_elem):\n",
    "        for frac_pattern in patterns:\n",
    "            comp_dict = dict(zip(elems, frac_pattern))\n",
    "            comp = Composition(comp_dict)\n",
    "            candidates.append({\n",
    "                \"formula\": comp.reduced_formula,\n",
    "                \"composition\": comp\n",
    "            })\n",
    "\n",
    "df_candidates = pd.DataFrame(candidates).drop_duplicates(\"formula\")\n",
    "\n",
    "df_candidates.to_csv(\n",
    "    TABLE_DIR / \"inverse_candidates_raw.csv\",\n",
    "    index=False\n",
    ")\n",
    "\n",
    "print(\"Raw inverse candidates:\", len(df_candidates))\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# 5. APPLY PHYSICS CONSTRAINTS\n",
    "# ------------------------------------------------------------\n",
    "mask = df_candidates[\"composition\"].apply(physics_constraints)\n",
    "df_filtered = df_candidates[mask].copy()\n",
    "\n",
    "df_filtered[\"n_elements\"] = df_filtered[\"composition\"].apply(\n",
    "    lambda c: len(c.fractional_composition.get_el_amt_dict())\n",
    ")\n",
    "\n",
    "df_filtered[\"composition_entropy\"] = df_filtered[\"composition\"].apply(\n",
    "    lambda c: -sum(\n",
    "        v * np.log(v)\n",
    "        for v in c.fractional_composition.get_el_amt_dict().values()\n",
    "    )\n",
    ")\n",
    "\n",
    "df_filtered[\"frac_3d_elements\"] = df_filtered[\"composition\"].apply(\n",
    "    lambda c: sum(\n",
    "        c.fractional_composition.get_el_amt_dict().get(e, 0)\n",
    "        for e in TM_3D\n",
    "    )\n",
    ")\n",
    "\n",
    "df_filtered[\"frac_RE_elements\"] = df_filtered[\"composition\"].apply(\n",
    "    lambda c: sum(\n",
    "        c.fractional_composition.get_el_amt_dict().get(e, 0)\n",
    "        for e in RARE_EARTHS\n",
    "    )\n",
    ")\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# 6. SAVE FILTERED POOL\n",
    "# ------------------------------------------------------------\n",
    "df_filtered.drop(columns=[\"composition\"]).to_csv(\n",
    "    TABLE_DIR / \"inverse_candidates_filtered.csv\",\n",
    "    index=False\n",
    ")\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# 7. GENERATION LOG (METHODS-READY)\n",
    "# ------------------------------------------------------------\n",
    "log = pd.DataFrame({\n",
    "    \"Stage\": [\"Raw generation\", \"After physics constraints\"],\n",
    "    \"Count\": [len(df_candidates), len(df_filtered)]\n",
    "})\n",
    "\n",
    "log.to_csv(\n",
    "    TABLE_DIR / \"inverse_generation_log.csv\",\n",
    "    index=False\n",
    ")\n",
    "\n",
    "print(\"Filtered inverse candidates:\", len(df_filtered))\n",
    "print(\"CELL 8A COMPLETED SUCCESSFULLY.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18bfa8aa-9f16-4b1c-84cc-35ffc77b81d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import joblib\n",
    "from pymatgen.core import Composition\n",
    "\n",
    "from matminer.featurizers.composition import (\n",
    "    ElementProperty,\n",
    "    Stoichiometry,\n",
    "    ValenceOrbital,\n",
    "    IonProperty,\n",
    "    AtomicOrbitals,\n",
    "    BandCenter\n",
    ")\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# 0. Paths\n",
    "# ------------------------------------------------------------\n",
    "INV_DIR = RESULTS_DIR / \"inverse_design\"\n",
    "TABLE_DIR = INV_DIR / \"tables\"\n",
    "MODEL_DIR = RESULTS_DIR\n",
    "\n",
    "TABLE_DIR.mkdir(exist_ok=True, parents=True)\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# 1. Load inverse candidates (from Cell 8A)\n",
    "# ------------------------------------------------------------\n",
    "df_inv = pd.read_csv(TABLE_DIR / \"inverse_candidates_filtered.csv\")\n",
    "print(\"Inverse candidate pool:\", df_inv.shape)\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# 2. Load TRAINING feature template (CRITICAL)\n",
    "# ------------------------------------------------------------\n",
    "df_train_feat = pd.read_csv(\n",
    "    DATA_INTERIM_DIR / \"Curie_Feature_Table_Magpie_Physics.csv\"\n",
    ")\n",
    "\n",
    "FEATURE_COLS = (\n",
    "    df_train_feat\n",
    "    .drop(columns=[\"Curie\"])\n",
    "    .select_dtypes(include=[np.number])\n",
    "    .columns\n",
    "    .tolist()\n",
    ")\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# 3. Recreate composition object\n",
    "# ------------------------------------------------------------\n",
    "df_inv[\"composition\"] = df_inv[\"formula\"].apply(Composition)\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# 4. MATMINER FEATURES ONLY (physics already exists)\n",
    "# ------------------------------------------------------------\n",
    "ep = ElementProperty.from_preset(\"magpie\")\n",
    "sto = Stoichiometry()\n",
    "val = ValenceOrbital(props=[\"avg\", \"frac\"])\n",
    "ion = IonProperty(fast=True)\n",
    "orb = AtomicOrbitals()\n",
    "bc = BandCenter()\n",
    "\n",
    "df_inv = ep.featurize_dataframe(df_inv, \"composition\", ignore_errors=True)\n",
    "df_inv = sto.featurize_dataframe(df_inv, \"composition\", ignore_errors=True)\n",
    "df_inv = val.featurize_dataframe(df_inv, \"composition\", ignore_errors=True)\n",
    "df_inv = ion.featurize_dataframe(df_inv, \"composition\", ignore_errors=True)\n",
    "df_inv = orb.featurize_dataframe(df_inv, \"composition\", ignore_errors=True)\n",
    "df_inv = bc.featurize_dataframe(df_inv, \"composition\", ignore_errors=True)\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# 5. Align inverse feature matrix to training features\n",
    "# ------------------------------------------------------------\n",
    "X_inv = (\n",
    "    df_inv\n",
    "    .select_dtypes(include=[np.number])\n",
    "    .reindex(columns=FEATURE_COLS)\n",
    ")\n",
    "\n",
    "print(\"Inverse feature matrix shape:\", X_inv.shape)\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# 6. Load trained models (ALL THREE)\n",
    "# ------------------------------------------------------------\n",
    "models = {\n",
    "    \"XGBoost\": joblib.load(MODEL_DIR / \"model_XGBoost.joblib\"),\n",
    "    \"RandomForest\": joblib.load(MODEL_DIR / \"model_RandomForest.joblib\"),\n",
    "    \"LightGBM\": joblib.load(MODEL_DIR / \"model_LightGBM.joblib\"),\n",
    "}\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# 7. Predict Tc (SEPARATELY FOR EACH MODEL)\n",
    "# ------------------------------------------------------------\n",
    "pred_tables = []\n",
    "\n",
    "for name, model in models.items():\n",
    "    print(f\"Predicting Tc using {name} ...\")\n",
    "\n",
    "    Tc_pred = model.predict(X_inv)\n",
    "\n",
    "    df_pred = pd.DataFrame({\n",
    "        \"formula\": df_inv[\"formula\"],\n",
    "        f\"Tc_{name}\": Tc_pred\n",
    "    }).sort_values(f\"Tc_{name}\", ascending=False)\n",
    "\n",
    "    df_pred.to_csv(\n",
    "        TABLE_DIR / f\"inverse_predictions_{name}.csv\",\n",
    "        index=False\n",
    "    )\n",
    "\n",
    "    pred_tables.append(df_pred.set_index(\"formula\"))\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# 8. Merge predictions across models\n",
    "# ------------------------------------------------------------\n",
    "df_all = pd.concat(pred_tables, axis=1).reset_index()\n",
    "\n",
    "df_all.to_csv(\n",
    "    TABLE_DIR / \"inverse_predictions_all_models.csv\",\n",
    "    index=False\n",
    ")\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# 9. Summary statistics (high-level sanity check)\n",
    "# ------------------------------------------------------------\n",
    "summary = pd.DataFrame({\n",
    "    \"Model\": list(models.keys()),\n",
    "    \"Max_Tc\": [df_all[f\"Tc_{m}\"].max() for m in models],\n",
    "    \"Mean_Top10\": [\n",
    "        df_all[f\"Tc_{m}\"].nlargest(10).mean() for m in models\n",
    "    ]\n",
    "})\n",
    "\n",
    "summary.to_csv(\n",
    "    TABLE_DIR / \"inverse_prediction_summary.csv\",\n",
    "    index=False\n",
    ")\n",
    "\n",
    "print(\"\\nInverse prediction summary:\")\n",
    "print(summary)\n",
    "\n",
    "print(\"\\nCELL 8B COMPLETED SUCCESSFULLY.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4ceb3d4-4250-44b8-adb2-ce1ee161fe20",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# 0. Paths\n",
    "# ------------------------------------------------------------\n",
    "INV_DIR = RESULTS_DIR / \"inverse_design\"\n",
    "TABLE_DIR = INV_DIR / \"tables\"\n",
    "TABLE_DIR.mkdir(exist_ok=True, parents=True)\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# 1. Load inverse prediction tables\n",
    "# ------------------------------------------------------------\n",
    "df_all = pd.read_csv(TABLE_DIR / \"inverse_predictions_all_models.csv\")\n",
    "df_base = pd.read_csv(TABLE_DIR / \"inverse_candidates_filtered.csv\")\n",
    "\n",
    "# Merge physics info\n",
    "df = df_all.merge(\n",
    "    df_base,\n",
    "    on=\"formula\",\n",
    "    how=\"left\"\n",
    ")\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# 2. MODEL AGREEMENT METRICS\n",
    "# ------------------------------------------------------------\n",
    "Tc_cols = [\"Tc_XGBoost\", \"Tc_RandomForest\", \"Tc_LightGBM\"]\n",
    "\n",
    "df[\"Tc_mean\"] = df[Tc_cols].mean(axis=1)\n",
    "df[\"Tc_std\"] = df[Tc_cols].std(axis=1)\n",
    "df[\"Tc_min\"] = df[Tc_cols].min(axis=1)\n",
    "\n",
    "# Agreement score: high mean, low disagreement\n",
    "df[\"agreement_score\"] = df[\"Tc_mean\"] / (1 + df[\"Tc_std\"])\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# 3. ERROR-AWARE RELIABILITY PENALTY\n",
    "# ------------------------------------------------------------\n",
    "# From Cell 7: ~1600 K = extreme MAE tail\n",
    "ERROR_SCALE = 1600.0\n",
    "\n",
    "df[\"reliability_score\"] = np.exp(\n",
    "    -df[\"Tc_std\"] / ERROR_SCALE\n",
    ")\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# 4. PHYSICS CONSISTENCY SCORE\n",
    "# ------------------------------------------------------------\n",
    "df[\"physics_score\"] = (\n",
    "    0.5 * df[\"frac_3d_elements\"]\n",
    "    - 0.3 * df[\"frac_RE_elements\"]\n",
    "    - 0.2 * df[\"composition_entropy\"]\n",
    ")\n",
    "\n",
    "# Normalize physics score\n",
    "df[\"physics_score\"] = (\n",
    "    df[\"physics_score\"] - df[\"physics_score\"].min()\n",
    ") / (\n",
    "    df[\"physics_score\"].max() - df[\"physics_score\"].min()\n",
    ")\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# 5. FINAL INVERSE SCORE\n",
    "# ------------------------------------------------------------\n",
    "df[\"inverse_score\"] = (\n",
    "    0.5 * df[\"agreement_score\"].rank(pct=True)\n",
    "    + 0.3 * df[\"reliability_score\"]\n",
    "    + 0.2 * df[\"physics_score\"]\n",
    ")\n",
    "\n",
    "df = df.sort_values(\"inverse_score\", ascending=False)\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# 6. SAVE FULL RANKED LIST\n",
    "# ------------------------------------------------------------\n",
    "df.to_csv(\n",
    "    TABLE_DIR / \"inverse_candidates_scored.csv\",\n",
    "    index=False\n",
    ")\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# 7. TOP CANDIDATES (PUBLICATION-GRADE)\n",
    "# ------------------------------------------------------------\n",
    "TOP_N = 50\n",
    "df_top = df.head(TOP_N)\n",
    "\n",
    "df_top.to_csv(\n",
    "    TABLE_DIR / \"inverse_candidates_top50.csv\",\n",
    "    index=False\n",
    ")\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# 8. AGREEMENT SUMMARY (METHODS-READY)\n",
    "# ------------------------------------------------------------\n",
    "summary = pd.DataFrame({\n",
    "    \"Metric\": [\n",
    "        \"Candidates generated\",\n",
    "        \"After physics constraints\",\n",
    "        \"After model agreement\",\n",
    "        \"Final shortlisted\"\n",
    "    ],\n",
    "    \"Count\": [\n",
    "        len(df_all),\n",
    "        len(df),\n",
    "        len(df[df[\"Tc_std\"] < 300]),\n",
    "        TOP_N\n",
    "    ]\n",
    "})\n",
    "\n",
    "summary.to_csv(\n",
    "    TABLE_DIR / \"inverse_candidate_statistics.csv\",\n",
    "    index=False\n",
    ")\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# 9. MODEL AGREEMENT TABLE\n",
    "# ------------------------------------------------------------\n",
    "agreement = df_top[[\n",
    "    \"formula\",\n",
    "    \"Tc_XGBoost\",\n",
    "    \"Tc_RandomForest\",\n",
    "    \"Tc_LightGBM\",\n",
    "    \"Tc_mean\",\n",
    "    \"Tc_std\",\n",
    "    \"inverse_score\"\n",
    "]]\n",
    "\n",
    "agreement.to_csv(\n",
    "    TABLE_DIR / \"inverse_agreement_summary.csv\",\n",
    "    index=False\n",
    ")\n",
    "\n",
    "print(\"\\nTOP 10 INVERSE CANDIDATES:\")\n",
    "print(agreement.head(10))\n",
    "\n",
    "print(\"\\nCELL 8C COMPLETED SUCCESSFULLY.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5bf0c4f-ce21-4fa1-ab5c-9a68ad4542c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# 0. Paths\n",
    "# ------------------------------------------------------------\n",
    "INV_DIR = RESULTS_DIR / \"inverse_design\"\n",
    "TABLE_DIR = INV_DIR / \"tables\"\n",
    "FIG_DIR = INV_DIR / \"figures\"\n",
    "\n",
    "FIG_DIR.mkdir(exist_ok=True, parents=True)\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# 1. Load FINAL ranked inverse candidates (from Cell 8C)\n",
    "# ------------------------------------------------------------\n",
    "df = pd.read_csv(\n",
    "    TABLE_DIR / \"inverse_candidates_scored.csv\"\n",
    ")\n",
    "\n",
    "print(\"Inverse candidates loaded:\", df.shape)\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# 2. Global summary statistics\n",
    "# ------------------------------------------------------------\n",
    "summary = df[[\n",
    "    \"Tc_mean\",\n",
    "    \"Tc_std\",\n",
    "    \"inverse_score\",\n",
    "    \"frac_3d_elements\",\n",
    "    \"frac_RE_elements\",\n",
    "    \"composition_entropy\"\n",
    "]].describe()\n",
    "\n",
    "summary.to_csv(\n",
    "    TABLE_DIR / \"inverse_physics_summary_statistics.csv\"\n",
    ")\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# 3. Tc vs 3d-element fraction\n",
    "# ------------------------------------------------------------\n",
    "fig, ax = plt.subplots()\n",
    "ax.scatter(\n",
    "    df[\"frac_3d_elements\"],\n",
    "    df[\"Tc_mean\"],\n",
    "    s=25,\n",
    "    alpha=0.6\n",
    ")\n",
    "ax.set_xlabel(\"Fraction of 3d transition metals\")\n",
    "ax.set_ylabel(\"Mean predicted Tc (K)\")\n",
    "ax.set_title(\"Tc vs 3d-element fraction (inverse candidates)\")\n",
    "save_figure(fig, \"Tc_vs_frac_3d_inverse\")\n",
    "plt.close(fig)\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# 4. Tc vs rare-earth fraction\n",
    "# ------------------------------------------------------------\n",
    "fig, ax = plt.subplots()\n",
    "ax.scatter(\n",
    "    df[\"frac_RE_elements\"],\n",
    "    df[\"Tc_mean\"],\n",
    "    s=25,\n",
    "    alpha=0.6,\n",
    "    color=\"darkred\"\n",
    ")\n",
    "ax.set_xlabel(\"Fraction of rare-earth elements\")\n",
    "ax.set_ylabel(\"Mean predicted Tc (K)\")\n",
    "ax.set_title(\"Tc vs rare-earth fraction (inverse candidates)\")\n",
    "save_figure(fig, \"Tc_vs_frac_RE_inverse\")\n",
    "plt.close(fig)\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# 5. Tc vs compositional entropy\n",
    "# ------------------------------------------------------------\n",
    "fig, ax = plt.subplots()\n",
    "ax.scatter(\n",
    "    df[\"composition_entropy\"],\n",
    "    df[\"Tc_mean\"],\n",
    "    s=25,\n",
    "    alpha=0.6,\n",
    "    color=\"darkgreen\"\n",
    ")\n",
    "ax.set_xlabel(\"Composition entropy\")\n",
    "ax.set_ylabel(\"Mean predicted Tc (K)\")\n",
    "ax.set_title(\"Tc vs entropy (inverse candidates)\")\n",
    "save_figure(fig, \"Tc_vs_entropy_inverse\")\n",
    "plt.close(fig)\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# 6. Inverse score vs Tc uncertainty\n",
    "# ------------------------------------------------------------\n",
    "fig, ax = plt.subplots()\n",
    "ax.scatter(\n",
    "    df[\"Tc_std\"],\n",
    "    df[\"inverse_score\"],\n",
    "    s=25,\n",
    "    alpha=0.6,\n",
    "    color=\"purple\"\n",
    ")\n",
    "ax.set_xlabel(\"Model disagreement (Tc std, K)\")\n",
    "ax.set_ylabel(\"Inverse score\")\n",
    "ax.set_title(\"Inverse score vs model uncertainty\")\n",
    "save_figure(fig, \"Inverse_score_vs_Tc_std\")\n",
    "plt.close(fig)\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# 7. Top candidates chemistry table (publication-ready)\n",
    "# ------------------------------------------------------------\n",
    "TOP_N = 20\n",
    "\n",
    "chem_table = df.head(TOP_N)[[\n",
    "    \"formula\",\n",
    "    \"Tc_XGBoost\",\n",
    "    \"Tc_RandomForest\",\n",
    "    \"Tc_LightGBM\",\n",
    "    \"Tc_mean\",\n",
    "    \"Tc_std\",\n",
    "    \"frac_3d_elements\",\n",
    "    \"frac_RE_elements\",\n",
    "    \"composition_entropy\",\n",
    "    \"inverse_score\"\n",
    "]]\n",
    "\n",
    "chem_table.to_csv(\n",
    "    TABLE_DIR / \"top20_inverse_candidates_physics.csv\",\n",
    "    index=False\n",
    ")\n",
    "\n",
    "print(\"\\nTop inverse candidates (physics view):\")\n",
    "print(chem_table.head(10))\n",
    "\n",
    "print(\"\\nCELL 8D COMPLETED SUCCESSFULLY.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84382944-5d19-4033-97d4-698eac38ed61",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# CELL 9A: SPINTRONIC PROXY DESCRIPTORS (CLEAN & ROBUST)\n",
    "# ============================================================\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# 0. Paths (CONSISTENT WITH NOTEBOOK)\n",
    "# ------------------------------------------------------------\n",
    "INV_DIR = RESULTS_DIR / \"inverse_design\"\n",
    "TABLE_DIR = INV_DIR / \"tables\"\n",
    "\n",
    "TABLE_DIR.mkdir(exist_ok=True, parents=True)\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# 1. Load inverse candidates with physics + Tc (from Cell 8C)\n",
    "# ------------------------------------------------------------\n",
    "df = pd.read_csv(TABLE_DIR / \"inverse_candidates_scored.csv\")\n",
    "\n",
    "print(\"Inverse candidates loaded:\", df.shape)\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# 2. SAFETY CHECK: REQUIRED COLUMNS\n",
    "# ------------------------------------------------------------\n",
    "required_cols = [\n",
    "    \"frac_3d_elements\",\n",
    "    \"frac_RE_elements\",\n",
    "    \"composition_entropy\",\n",
    "    \"inverse_score\",\n",
    "    \"Tc_mean\"\n",
    "]\n",
    "\n",
    "missing = [c for c in required_cols if c not in df.columns]\n",
    "if missing:\n",
    "    raise KeyError(f\"Missing required columns: {missing}\")\n",
    "\n",
    "# Optional Magpie columns (may or may not exist)\n",
    "HAS_GAP = \"MagpieData mean GSbandgap\" in df.columns\n",
    "HAS_COVDEV = \"MagpieData avg_dev CovalentRadius\" in df.columns\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# 3. SPINTRONIC PROXY DEFINITIONS (NO DFT)\n",
    "# ------------------------------------------------------------\n",
    "def spintronic_proxies(row):\n",
    "    frac_3d = row[\"frac_3d_elements\"]\n",
    "    frac_re = row[\"frac_RE_elements\"]\n",
    "    entropy = row[\"composition_entropy\"]\n",
    "\n",
    "    # ---- Exchange network strength ----\n",
    "    exchange_proxy = frac_3d * (1.0 - frac_re)\n",
    "\n",
    "    # ---- Spin polarization tendency ----\n",
    "    spin_polarization_proxy = frac_3d / (1.0 + entropy)\n",
    "\n",
    "    # ---- Metallic transport proxy ----\n",
    "    if HAS_GAP:\n",
    "        gap = row[\"MagpieData mean GSbandgap\"]\n",
    "        metallicity_proxy = np.exp(-gap)\n",
    "    else:\n",
    "        metallicity_proxy = 1.0  # assume metallic if unknown\n",
    "\n",
    "    # ---- Disorder / scattering proxy ----\n",
    "    if HAS_COVDEV:\n",
    "        cov_dev = row[\"MagpieData avg_dev CovalentRadius\"]\n",
    "        scattering_proxy = np.exp(-cov_dev)\n",
    "    else:\n",
    "        scattering_proxy = 1.0  # no penalty if unknown\n",
    "\n",
    "    # ---- Composite spintronics score ----\n",
    "    spintronics_score = (\n",
    "        0.35 * exchange_proxy +\n",
    "        0.25 * spin_polarization_proxy +\n",
    "        0.20 * metallicity_proxy +\n",
    "        0.20 * scattering_proxy\n",
    "    )\n",
    "\n",
    "    return pd.Series({\n",
    "        \"exchange_proxy\": exchange_proxy,\n",
    "        \"spin_polarization_proxy\": spin_polarization_proxy,\n",
    "        \"metallicity_proxy\": metallicity_proxy,\n",
    "        \"scattering_proxy\": scattering_proxy,\n",
    "        \"spintronics_score\": spintronics_score\n",
    "    })\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# 4. APPLY SPINTRONIC PROXIES\n",
    "# ------------------------------------------------------------\n",
    "df_spin = df.join(df.apply(spintronic_proxies, axis=1))\n",
    "\n",
    "print(\"Spintronic proxy features added.\")\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# 5. NORMALIZE & FINAL DEVICE SCORE\n",
    "# ------------------------------------------------------------\n",
    "df_spin[\"spintronics_score_norm\"] = (\n",
    "    df_spin[\"spintronics_score\"] - df_spin[\"spintronics_score\"].min()\n",
    ") / (\n",
    "    df_spin[\"spintronics_score\"].max()\n",
    "    - df_spin[\"spintronics_score\"].min()\n",
    ")\n",
    "\n",
    "# Device-oriented final score\n",
    "df_spin[\"final_device_score\"] = (\n",
    "    0.6 * df_spin[\"inverse_score\"] +\n",
    "    0.4 * df_spin[\"spintronics_score_norm\"]\n",
    ")\n",
    "\n",
    "df_spin = df_spin.sort_values(\n",
    "    \"final_device_score\", ascending=False\n",
    ")\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# 6. SAVE RESULTS (FULL + TOP)\n",
    "# ------------------------------------------------------------\n",
    "df_spin.to_csv(\n",
    "    TABLE_DIR / \"inverse_candidates_with_spintronics.csv\",\n",
    "    index=False\n",
    ")\n",
    "\n",
    "TOP_N = 50\n",
    "df_spin.head(TOP_N).to_csv(\n",
    "    TABLE_DIR / \"inverse_candidates_spintronics_top50.csv\",\n",
    "    index=False\n",
    ")\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# 7. METHODS-READY SUMMARY\n",
    "# ------------------------------------------------------------\n",
    "summary = pd.DataFrame({\n",
    "    \"Stage\": [\n",
    "        \"Inverse candidates (physics filtered)\",\n",
    "        \"Spintronics evaluated\",\n",
    "        \"Final shortlisted\"\n",
    "    ],\n",
    "    \"Count\": [\n",
    "        len(df),\n",
    "        len(df_spin),\n",
    "        TOP_N\n",
    "    ]\n",
    "})\n",
    "\n",
    "summary.to_csv(\n",
    "    TABLE_DIR / \"spintronics_screening_summary.csv\",\n",
    "    index=False\n",
    ")\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# 8. QUICK SANITY PRINT\n",
    "# ------------------------------------------------------------\n",
    "print(\"\\nTOP 10 SPINTRONICALLY PROMISING CANDIDATES:\")\n",
    "print(\n",
    "    df_spin[[\n",
    "        \"formula\",\n",
    "        \"Tc_mean\",\n",
    "        \"exchange_proxy\",\n",
    "        \"spin_polarization_proxy\",\n",
    "        \"metallicity_proxy\",\n",
    "        \"scattering_proxy\",\n",
    "        \"spintronics_score\",\n",
    "        \"final_device_score\"\n",
    "    ]].head(10)\n",
    ")\n",
    "\n",
    "print(\"\\nCELL 9A COMPLETED SUCCESSFULLY.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "995296f3-8569-4d48-94d8-49e51372928b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# 0. Paths\n",
    "# ------------------------------------------------------------\n",
    "INV_DIR = RESULTS_DIR / \"inverse_design\"\n",
    "TABLE_DIR = INV_DIR / \"tables\"\n",
    "FIG_DIR_PNG = RESULTS_DIR / \"figures\" / \"png\"\n",
    "FIG_DIR_PDF = RESULTS_DIR / \"figures\" / \"pdf\"\n",
    "\n",
    "FIG_DIR_PNG.mkdir(exist_ok=True, parents=True)\n",
    "FIG_DIR_PDF.mkdir(exist_ok=True, parents=True)\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# 1. Load spintronics-ranked inverse candidates (from Cell 9A)\n",
    "# ------------------------------------------------------------\n",
    "df = pd.read_csv(TABLE_DIR / \"inverse_candidates_with_spintronics.csv\")\n",
    "\n",
    "print(\"Loaded spintronics-evaluated candidates:\", df.shape)\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# 2. Select TOP candidates for radar visualization\n",
    "# ------------------------------------------------------------\n",
    "TOP_K = 5\n",
    "df_top = df.head(TOP_K).copy()\n",
    "\n",
    "# Metrics to visualize (all normalized or bounded)\n",
    "RADAR_FEATURES = [\n",
    "    \"Tc_mean\",\n",
    "    \"exchange_proxy\",\n",
    "    \"spin_polarization_proxy\",\n",
    "    \"metallicity_proxy\",\n",
    "    \"scattering_proxy\",\n",
    "    \"inverse_score\"\n",
    "]\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# 3. Normalize features for radar (0–1)\n",
    "# ------------------------------------------------------------\n",
    "df_radar = df_top[[\"formula\"] + RADAR_FEATURES].copy()\n",
    "\n",
    "for col in RADAR_FEATURES:\n",
    "    min_v = df[col].min()\n",
    "    max_v = df[col].max()\n",
    "    if max_v > min_v:\n",
    "        df_radar[col] = (df_radar[col] - min_v) / (max_v - min_v)\n",
    "    else:\n",
    "        df_radar[col] = 0.5  # fallback\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# 4. Radar plot function\n",
    "# ------------------------------------------------------------\n",
    "def radar_plot(df_radar, features, title, fname):\n",
    "    labels = features\n",
    "    num_vars = len(labels)\n",
    "\n",
    "    angles = np.linspace(0, 2 * np.pi, num_vars, endpoint=False).tolist()\n",
    "    angles += angles[:1]\n",
    "\n",
    "    fig, ax = plt.subplots(\n",
    "        figsize=(7, 7),\n",
    "        subplot_kw=dict(polar=True)\n",
    "    )\n",
    "\n",
    "    for _, row in df_radar.iterrows():\n",
    "        values = row[features].tolist()\n",
    "        values += values[:1]\n",
    "\n",
    "        ax.plot(angles, values, linewidth=2, label=row[\"formula\"])\n",
    "        ax.fill(angles, values, alpha=0.15)\n",
    "\n",
    "    ax.set_theta_offset(np.pi / 2)\n",
    "    ax.set_theta_direction(-1)\n",
    "\n",
    "    ax.set_thetagrids(\n",
    "        np.degrees(angles[:-1]),\n",
    "        labels\n",
    "    )\n",
    "\n",
    "    ax.set_ylim(0, 1)\n",
    "    ax.set_title(title, fontsize=14, pad=20)\n",
    "    ax.legend(\n",
    "        loc=\"upper right\",\n",
    "        bbox_to_anchor=(1.35, 1.15),\n",
    "        fontsize=9\n",
    "    )\n",
    "\n",
    "    # Save\n",
    "    fig.savefig(FIG_DIR_PNG / f\"{fname}.png\", dpi=300, bbox_inches=\"tight\")\n",
    "    fig.savefig(FIG_DIR_PDF / f\"{fname}.pdf\", bbox_inches=\"tight\")\n",
    "    plt.close(fig)\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# 5. Generate radar plot\n",
    "# ------------------------------------------------------------\n",
    "radar_plot(\n",
    "    df_radar,\n",
    "    RADAR_FEATURES,\n",
    "    title=\"Spintronic Signature Radar — Top Inverse Candidates\",\n",
    "    fname=\"spintronics_radar_top5\"\n",
    ")\n",
    "\n",
    "print(\"Saved radar plots:\")\n",
    "print(\" -\", FIG_DIR_PNG / \"spintronics_radar_top5.png\")\n",
    "print(\" -\", FIG_DIR_PDF / \"spintronics_radar_top5.pdf\")\n",
    "\n",
    "print(\"\\nCELL 9B COMPLETED SUCCESSFULLY.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1829a39-8597-4704-b4ef-1e811ad486ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# 0. Paths\n",
    "# ------------------------------------------------------------\n",
    "INV_DIR = RESULTS_DIR / \"inverse_design\"\n",
    "TABLE_DIR = INV_DIR / \"tables\"\n",
    "FIG_PNG = RESULTS_DIR / \"figures\" / \"png\"\n",
    "FIG_PDF = RESULTS_DIR / \"figures\" / \"pdf\"\n",
    "\n",
    "FIG_PNG.mkdir(exist_ok=True, parents=True)\n",
    "FIG_PDF.mkdir(exist_ok=True, parents=True)\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# 1. Load spintronics-ranked candidates\n",
    "# ------------------------------------------------------------\n",
    "df = pd.read_csv(TABLE_DIR / \"inverse_candidates_with_spintronics.csv\")\n",
    "\n",
    "print(\"Spintronics-evaluated dataset:\", df.shape)\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# 2. DEFINE CHEMISTRY CLASSES (RULE-BASED, TRANSPARENT)\n",
    "# ------------------------------------------------------------\n",
    "def chemistry_family(formula):\n",
    "    if any(x in formula for x in [\"Fe\", \"Co\", \"Ni\"]):\n",
    "        return \"Fe–Co–Ni based\"\n",
    "    if \"Mn\" in formula:\n",
    "        return \"Mn-based\"\n",
    "    if any(x in formula for x in [\"Cr\", \"V\"]):\n",
    "        return \"Cr/V-based\"\n",
    "    return \"Other\"\n",
    "\n",
    "df[\"chemistry_family\"] = df[\"formula\"].apply(chemistry_family)\n",
    "\n",
    "# Binary vs ternary vs quaternary\n",
    "df[\"complexity\"] = df[\"formula\"].str.count(r\"[A-Z]\")  # proxy\n",
    "\n",
    "def complexity_class(n):\n",
    "    if n == 2:\n",
    "        return \"Binary\"\n",
    "    if n == 3:\n",
    "        return \"Ternary\"\n",
    "    return \"Higher-order\"\n",
    "\n",
    "df[\"complexity_class\"] = df[\"complexity\"].apply(complexity_class)\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# 3. AGGREGATED STATISTICS BY CHEMISTRY FAMILY\n",
    "# ------------------------------------------------------------\n",
    "chem_stats = (\n",
    "    df.groupby(\"chemistry_family\")\n",
    "    .agg(\n",
    "        count=(\"formula\", \"count\"),\n",
    "        Tc_mean=(\"Tc_mean\", \"mean\"),\n",
    "        Tc_std=(\"Tc_std\", \"mean\"),\n",
    "        spintronics_score=(\"spintronics_score\", \"mean\"),\n",
    "        final_device_score=(\"final_device_score\", \"mean\"),\n",
    "        entropy=(\"composition_entropy\", \"mean\")\n",
    "    )\n",
    "    .sort_values(\"final_device_score\", ascending=False)\n",
    ")\n",
    "\n",
    "chem_stats.to_csv(\n",
    "    TABLE_DIR / \"spintronics_by_chemistry_family.csv\"\n",
    ")\n",
    "\n",
    "print(\"\\nCHEMISTRY FAMILY SUMMARY:\")\n",
    "print(chem_stats)\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# 4. AGGREGATED STATISTICS BY CHEMICAL COMPLEXITY\n",
    "# ------------------------------------------------------------\n",
    "comp_stats = (\n",
    "    df.groupby(\"complexity_class\")\n",
    "    .agg(\n",
    "        count=(\"formula\", \"count\"),\n",
    "        Tc_mean=(\"Tc_mean\", \"mean\"),\n",
    "        Tc_std=(\"Tc_std\", \"mean\"),\n",
    "        spintronics_score=(\"spintronics_score\", \"mean\"),\n",
    "        final_device_score=(\"final_device_score\", \"mean\"),\n",
    "        entropy=(\"composition_entropy\", \"mean\")\n",
    "    )\n",
    "    .sort_values(\"final_device_score\", ascending=False)\n",
    ")\n",
    "\n",
    "comp_stats.to_csv(\n",
    "    TABLE_DIR / \"spintronics_by_complexity.csv\"\n",
    ")\n",
    "\n",
    "print(\"\\nCHEMICAL COMPLEXITY SUMMARY:\")\n",
    "print(comp_stats)\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# 5. VISUALIZATION — CHEMISTRY FAMILY COMPARISON\n",
    "# ------------------------------------------------------------\n",
    "fig, ax = plt.subplots(figsize=(7, 5))\n",
    "chem_stats[\"final_device_score\"].plot(\n",
    "    kind=\"bar\",\n",
    "    ax=ax\n",
    ")\n",
    "ax.set_ylabel(\"Mean final device score\")\n",
    "ax.set_title(\"Spintronic performance by chemistry family\")\n",
    "ax.grid(axis=\"y\", alpha=0.3)\n",
    "\n",
    "fig.savefig(FIG_PNG / \"spintronics_by_chemistry_family.png\", dpi=300, bbox_inches=\"tight\")\n",
    "fig.savefig(FIG_PDF / \"spintronics_by_chemistry_family.pdf\", bbox_inches=\"tight\")\n",
    "plt.close(fig)\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# 6. VISUALIZATION — COMPLEXITY TRADE-OFF\n",
    "# ------------------------------------------------------------\n",
    "fig, ax = plt.subplots(figsize=(7, 5))\n",
    "comp_stats[\"final_device_score\"].plot(\n",
    "    kind=\"bar\",\n",
    "    ax=ax,\n",
    "    color=\"tab:orange\"\n",
    ")\n",
    "ax.set_ylabel(\"Mean final device score\")\n",
    "ax.set_title(\"Spintronic performance vs chemical complexity\")\n",
    "ax.grid(axis=\"y\", alpha=0.3)\n",
    "\n",
    "fig.savefig(FIG_PNG / \"spintronics_by_complexity.png\", dpi=300, bbox_inches=\"tight\")\n",
    "fig.savefig(FIG_PDF / \"spintronics_by_complexity.pdf\", bbox_inches=\"tight\")\n",
    "plt.close(fig)\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# 7. DESIGN-RULE TABLE (DISCUSSION-READY)\n",
    "# ------------------------------------------------------------\n",
    "design_rules = pd.DataFrame({\n",
    "    \"Observation\": [\n",
    "        \"Fe–Co–Ni alloys dominate top-ranked spintronic candidates\",\n",
    "        \"Binary systems outperform ternary systems on average\",\n",
    "        \"Higher entropy correlates with reduced device score\",\n",
    "        \"Mn-based alloys show moderate Tc but higher disorder penalty\"\n",
    "    ],\n",
    "    \"Implication\": [\n",
    "        \"Itinerant 3d exchange is the primary driver of spintronic performance\",\n",
    "        \"Low chemical complexity favors coherent spin transport\",\n",
    "        \"Entropy reduction is critical for reliable spintronics\",\n",
    "        \"Mn systems may require structural ordering or substrates\"\n",
    "    ]\n",
    "})\n",
    "\n",
    "design_rules.to_csv(\n",
    "    TABLE_DIR / \"spintronics_design_rules.csv\",\n",
    "    index=False\n",
    ")\n",
    "\n",
    "print(\"\\nDESIGN RULES TABLE GENERATED.\")\n",
    "\n",
    "print(\"\\nCELL 9C COMPLETED SUCCESSFULLY.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1494b848-fc1b-4fa1-824a-e34dc2d82a35",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
